{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:39:55.120765Z",
     "iopub.status.busy": "2024-10-15T11:39:55.119797Z",
     "iopub.status.idle": "2024-10-15T11:42:29.760002Z",
     "shell.execute_reply": "2024-10-15T11:42:29.758757Z",
     "shell.execute_reply.started": "2024-10-15T11:39:55.120705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install iterative-stratification\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install detectron2 -f \\https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:29.762314Z",
     "iopub.status.busy": "2024-10-15T11:42:29.762001Z",
     "iopub.status.idle": "2024-10-15T11:42:38.130928Z",
     "shell.execute_reply": "2024-10-15T11:42:38.130087Z",
     "shell.execute_reply.started": "2024-10-15T11:42:29.762279Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- setup ---\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define custom dataset, we need to create list of dict (dataset_dicts) where each dict contains following:\n",
    "\n",
    "file_name: file name of the image.\n",
    "\n",
    "image_id: id of the image, index is used here.\n",
    "\n",
    "height: height of the image.\n",
    "\n",
    "width: width of the image.\n",
    "\n",
    "annotation: This is the ground truth annotation data for object detection, which contains following\n",
    "\n",
    "bbox: bounding box pixel location with shape (n_boxes, 4)\n",
    "\n",
    "bbox_mode: BoxMode.XYXY_ABS is used here, meaning that absolute value of (xmin, ymin, xmax, ymax) annotation is used in the bbox.\n",
    "\n",
    "category_id: class label id for each bounding box, with shape (n_boxes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:38.133455Z",
     "iopub.status.busy": "2024-10-15T11:42:38.132407Z",
     "iopub.status.idle": "2024-10-15T11:42:39.884235Z",
     "shell.execute_reply": "2024-10-15T11:42:39.883432Z",
     "shell.execute_reply.started": "2024-10-15T11:42:38.133407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_custom_dicts(\n",
    "    imgdir: Path,\n",
    "    train_df: pd.DataFrame,\n",
    "    train_data_type: str = \"original\",\n",
    "    use_cache: bool = True,\n",
    "    debug: bool = True,\n",
    "    target_image_ids: Optional[np.ndarray] = None,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    train_data_type_str = f\"_{train_data_type}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache{train_data_type_str}{debug_str}.pkl\"\n",
    "    \n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        train_meta = pd.read_csv(imgdir / \"train_meta.csv\")\n",
    "        if debug:\n",
    "            train_meta = train_meta.iloc[:200]  # Debug mode: reduce dataset size\n",
    "\n",
    "        # Load the first image to obtain the resized image dimensions\n",
    "        first_image_id = train_meta.loc[0, \"image_id\"]\n",
    "        first_image_path = str(imgdir / \"TRAIN_DETECTRON2\" / f\"{first_image_id}.png\")\n",
    "        first_image = cv2.imread(first_image_path)\n",
    "        if first_image is None:\n",
    "            raise FileNotFoundError(f\"First image not found: {first_image_path}\")\n",
    "        resized_height, resized_width, ch = first_image.shape\n",
    "        print(f\"Image shape: {first_image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, train_meta_row in tqdm(train_meta.iterrows(), total=len(train_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = train_meta_row.values\n",
    "            filename = str(imgdir / \"TRAIN_DETECTRON2\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "\n",
    "            objs = []\n",
    "            for index2, row in train_df.query(\"image_id == @image_id\").iterrows():\n",
    "                \n",
    "                class_id = row[\"class_id\"]\n",
    "\n",
    "                # Rescale the bounding box based on the resized image dimensions\n",
    "                h_ratio = resized_height / height\n",
    "                w_ratio = resized_width / width\n",
    "                bbox_resized = [\n",
    "                    float(row[\"x_min\"]) * w_ratio,\n",
    "                    float(row[\"y_min\"]) * h_ratio,\n",
    "                    float(row[\"x_max\"]) * w_ratio,\n",
    "                    float(row[\"y_max\"]) * h_ratio,\n",
    "                ]\n",
    "                obj = {\n",
    "                    \"bbox\": bbox_resized,\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"category_id\": class_id,\n",
    "                }\n",
    "                objs.append(obj)\n",
    "\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    else:\n",
    "        print(f\"Loading from cache {cache_path}\")\n",
    "        with open(cache_path, mode=\"rb\") as f:\n",
    "            dataset_dicts = pickle.load(f)\n",
    "    \n",
    "    # Correct filtering logic for string-based image IDs\n",
    "    if target_image_ids is not None:\n",
    "        target_image_ids_set = set(target_image_ids)\n",
    "        dataset_dicts = [d for d in dataset_dicts if d[\"image_id\"] in target_image_ids_set]\n",
    "    \n",
    "    return dataset_dicts\n",
    "\n",
    "def get_custom_dicts_test(\n",
    "    imgdir: Path,\n",
    "    test_meta: pd.DataFrame,\n",
    "    use_cache: bool = True,\n",
    "    debug: bool = True,\n",
    "    target_image_ids: Optional[np.ndarray] = None,  # Added parameter\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache_test{debug_str}.pkl\"\n",
    "    \n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        if debug:\n",
    "            test_meta = test_meta.iloc[:200]  # Reduce data size in debug mode.\n",
    "\n",
    "        # Load the first image to obtain the resized image dimensions\n",
    "        first_image_id = test_meta.loc[0, \"image_id\"]\n",
    "        first_image_path = str(imgdir / \"TEST_DETECTRON2\" / f\"{first_image_id}.png\")\n",
    "        first_image = cv2.imread(first_image_path)\n",
    "        if first_image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {first_image_path}\")\n",
    "        resized_height, resized_width, ch = first_image.shape\n",
    "        print(f\"Image shape: {first_image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, test_meta_row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = test_meta_row.values\n",
    "            filename = str(imgdir / \"TEST_DETECTRON2\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "\n",
    "            dataset_dicts.append(record)\n",
    "\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    else:\n",
    "        print(f\"Loading from cache {cache_path}\")\n",
    "        with open(cache_path, mode=\"rb\") as f:\n",
    "            dataset_dicts = pickle.load(f)\n",
    "    \n",
    "    # Correct filtering logic for string-based image IDs\n",
    "    if target_image_ids is not None:\n",
    "        target_image_ids_set = set(target_image_ids)\n",
    "        dataset_dicts = [d for d in dataset_dicts if d[\"image_id\"] in target_image_ids_set]\n",
    "    \n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:39.887835Z",
     "iopub.status.busy": "2024-10-15T11:42:39.886741Z",
     "iopub.status.idle": "2024-10-15T11:42:39.893613Z",
     "shell.execute_reply": "2024-10-15T11:42:39.892748Z",
     "shell.execute_reply.started": "2024-10-15T11:42:39.887786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- utils ---\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_yaml(filepath: Union[str, Path], content: Any, width: int = 120):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(content, f, width=width)\n",
    "\n",
    "\n",
    "def load_yaml(filepath: Union[str, Path]) -> Any:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        content = yaml.full_load(f)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:39.895231Z",
     "iopub.status.busy": "2024-10-15T11:42:39.894938Z",
     "iopub.status.idle": "2024-10-15T11:42:39.905649Z",
     "shell.execute_reply": "2024-10-15T11:42:39.904787Z",
     "shell.execute_reply.started": "2024-10-15T11:42:39.895201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- configs ---\n",
    "thing_classes = [\n",
    "    \"bina\",\n",
    "    \"yol_kesisimi\",\n",
    "    \"futbol_sahası\",\n",
    "    \"silo\"\n",
    "]\n",
    "category_name_to_id = {class_name: index for index, class_name in enumerate(thing_classes)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Detectron2 Trainer\n",
    "## Mapper For Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:39.907748Z",
     "iopub.status.busy": "2024-10-15T11:42:39.907019Z",
     "iopub.status.idle": "2024-10-15T11:42:39.995582Z",
     "shell.execute_reply": "2024-10-15T11:42:39.994866Z",
     "shell.execute_reply.started": "2024-10-15T11:42:39.907704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Referenced:\n",
    " - https://detectron2.readthedocs.io/en/latest/tutorials/data_loading.html\n",
    " - https://www.kaggle.com/dhiiyaur/detectron-2-compare-models-augmentation/#data\n",
    "\"\"\"\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "import torch\n",
    "from detectron2.data import detection_utils as utils\n",
    "\n",
    "\n",
    "class MyMapper:\n",
    "    \"\"\"Mapper which uses `detectron2.data.transforms` augmentations\"\"\"\n",
    "\n",
    "    def __init__(self, cfg, is_train: bool = True):\n",
    "        aug_kwargs = cfg.aug_kwargs\n",
    "        aug_list = [\n",
    "        ]\n",
    "        if is_train:\n",
    "            # Making augmentation while training\n",
    "            aug_list.extend([getattr(T, name)(**kwargs) for name, kwargs in aug_kwargs.items()])\n",
    "        self.augmentations = T.AugmentationList(aug_list)\n",
    "        self.is_train = is_train\n",
    "\n",
    "        mode = \"training\" if is_train else \"inference\"\n",
    "        print(f\"[MyDatasetMapper] Augmentations used in {mode}: {self.augmentations}\")\n",
    "\n",
    "    def __call__(self, dataset_dict):\n",
    "        dataset_dict = copy.deepcopy(dataset_dict)  \n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=\"RGB\")  \n",
    "\n",
    "        aug_input = T.AugInput(image)\n",
    "        transforms = self.augmentations(aug_input)\n",
    "        image = aug_input.image\n",
    "\n",
    "        image_shape = image.shape[:2]  # h, w\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "        annos = [\n",
    "            utils.transform_instance_annotations(obj, transforms, image_shape)\n",
    "            for obj in dataset_dict.pop(\"annotations\")\n",
    "            if obj.get(\"iscrowd\", 0) == 0 \n",
    "        ]\n",
    "\n",
    "        instances = utils.annotations_to_instances(annos, image_shape)\n",
    "        dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "        \n",
    "        return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:39.997856Z",
     "iopub.status.busy": "2024-10-15T11:42:39.997078Z",
     "iopub.status.idle": "2024-10-15T11:42:40.857028Z",
     "shell.execute_reply": "2024-10-15T11:42:40.856043Z",
     "shell.execute_reply.started": "2024-10-15T11:42:39.997810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning:\n",
      "\n",
      "A new version of Albumentations is available: 1.4.18 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Referenced:\n",
    " - https://detectron2.readthedocs.io/en/latest/tutorials/data_loading.html\n",
    " - https://www.kaggle.com/dhiiyaur/detectron-2-compare-models-augmentation/#data\n",
    "\"\"\"\n",
    "import albumentations as A\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "\n",
    "class AlbumentationsMapper:\n",
    "    \"\"\"Mapper which uses albumentations augmentations\"\"\"\n",
    "    def __init__(self, cfg, is_train: bool = True):\n",
    "        aug_kwargs = cfg.aug_kwargs\n",
    "        aug_list = []\n",
    "        \n",
    "        if is_train:\n",
    "\n",
    "            aug_list.extend([getattr(A, name)(**kwargs) for name, kwargs in aug_kwargs.items()])\n",
    "        \n",
    "        self.transform = A.Compose(\n",
    "            aug_list, bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"category_ids\"])\n",
    "        )\n",
    "        self.is_train = is_train\n",
    "\n",
    "        mode = \"training\" if is_train else \"inference\"\n",
    "        print(f\"[AlbumentationsMapper] Augmentations used in {mode}: {self.transform}\")\n",
    "\n",
    "    def __call__(self, dataset_dict):\n",
    "        dataset_dict = copy.deepcopy(dataset_dict)  \n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=\"RGB\") \n",
    "\n",
    "        prev_anno = dataset_dict[\"annotations\"]\n",
    "        bboxes = np.array([obj[\"bbox\"] for obj in prev_anno], dtype=np.float32)\n",
    "        category_id = np.arange(len(dataset_dict[\"annotations\"]))\n",
    "\n",
    "        transformed = self.transform(image=image, bboxes=bboxes, category_ids=category_id)\n",
    "        image = transformed[\"image\"]\n",
    "\n",
    "        annos = []\n",
    "        for i, j in enumerate(transformed[\"category_ids\"]):\n",
    "            d = prev_anno[j]\n",
    "            d[\"bbox\"] = transformed[\"bboxes\"][i]\n",
    "            annos.append(d)\n",
    "        dataset_dict.pop(\"annotations\", None)  \n",
    "\n",
    "        image_shape = image.shape[:2]  \n",
    "        dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "        instances = utils.annotations_to_instances(annos, image_shape)\n",
    "\n",
    "        dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "        \n",
    "        return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Factor Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:40.859082Z",
     "iopub.status.busy": "2024-10-15T11:42:40.858372Z",
     "iopub.status.idle": "2024-10-15T11:42:40.866765Z",
     "shell.execute_reply": "2024-10-15T11:42:40.865991Z",
     "shell.execute_reply.started": "2024-10-15T11:42:40.859034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_class_frequencies(dataset_dict, num_classes):\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for record in dataset_dict:\n",
    "        for annotation in record[\"annotations\"]:\n",
    "            class_id = annotation[\"category_id\"]\n",
    "            class_counts[class_id] += 1\n",
    "    \n",
    "    return [class_counts[i] for i in range(num_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:40.868237Z",
     "iopub.status.busy": "2024-10-15T11:42:40.867912Z",
     "iopub.status.idle": "2024-10-15T11:42:40.877331Z",
     "shell.execute_reply": "2024-10-15T11:42:40.876542Z",
     "shell.execute_reply.started": "2024-10-15T11:42:40.868174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from detectron2.data.samplers import RepeatFactorTrainingSampler\n",
    "\n",
    "def get_repeat_factors(dataset_dicts, class_frequencies, repeat_threshold=0.01):\n",
    "    # Toplam örnek sayısı\n",
    "    total_samples = sum(class_frequencies)\n",
    "    \n",
    "    repeat_factors = []\n",
    "    for record in dataset_dicts:\n",
    "        class_ids = [anno[\"category_id\"] for anno in record[\"annotations\"]]\n",
    "        max_class_freq = max([class_frequencies[class_id] for class_id in class_ids])\n",
    "        \n",
    "        # Calculating repeat factor for rare classes\n",
    "        repeat_factor = max(1.0, (repeat_threshold * total_samples) / max_class_freq)\n",
    "        repeat_factors.append(repeat_factor)\n",
    "    \n",
    "    return torch.tensor(repeat_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:40.881184Z",
     "iopub.status.busy": "2024-10-15T11:42:40.880858Z",
     "iopub.status.idle": "2024-10-15T11:42:41.192327Z",
     "shell.execute_reply": "2024-10-15T11:42:41.191415Z",
     "shell.execute_reply.started": "2024-10-15T11:42:40.881152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "import contextlib\n",
    "import copy\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import pycocotools.mask as mask_util\n",
    "import torch\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from tabulate import tabulate\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.config import CfgNode\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.evaluation.fast_eval_api import COCOeval_opt\n",
    "from detectron2.structures import Boxes, BoxMode, pairwise_iou\n",
    "from detectron2.utils.file_io import PathManager\n",
    "from detectron2.utils.logger import create_small_table\n",
    "\n",
    "\n",
    "class SayzekEvaluator(DatasetEvaluator):\n",
    "    \"\"\"\n",
    "    Evaluate AR for object proposals, AP for instance detection/segmentation, AP\n",
    "    for keypoint detection outputs using COCO's metrics.\n",
    "    See http://cocodataset.org/#detection-eval and\n",
    "    http://cocodataset.org/#keypoints-eval to understand its metrics.\n",
    "\n",
    "    In addition to COCO, this evaluator is able to support any bounding box detection,\n",
    "    instance segmentation, or keypoint detection dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name,\n",
    "        tasks=None,\n",
    "        distributed=True,\n",
    "        output_dir=None,\n",
    "        *,\n",
    "        use_fast_impl=True,\n",
    "        kpt_oks_sigmas=(),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_name (str): name of the dataset to be evaluated.\n",
    "                It must have either the following corresponding metadata:\n",
    "\n",
    "                    \"json_file\": the path to the COCO format annotation\n",
    "\n",
    "                Or it must be in detectron2's standard dataset format\n",
    "                so it can be converted to COCO format automatically.\n",
    "            tasks (tuple[str]): tasks that can be evaluated under the given\n",
    "                configuration. A task is one of \"bbox\", \"segm\", \"keypoints\".\n",
    "                By default, will infer this automatically from predictions.\n",
    "            distributed (True): if True, will collect results from all ranks and run evaluation\n",
    "                in the main process.\n",
    "                Otherwise, will only evaluate the results in the current process.\n",
    "            output_dir (str): optional, an output directory to dump all\n",
    "                results predicted on the dataset. The dump contains two files:\n",
    "\n",
    "                1. \"instances_predictions.pth\" a file in torch serialization\n",
    "                   format that contains all the raw original predictions.\n",
    "                2. \"coco_instances_results.json\" a json file in COCO's result\n",
    "                   format.\n",
    "            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.\n",
    "                Although the results should be very close to the official implementation in COCO\n",
    "                API, it is still recommended to compute results with the official API for use in\n",
    "                papers. The faster implementation also uses more RAM.\n",
    "            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.\n",
    "                See http://cocodataset.org/#keypoints-eval\n",
    "                When empty, it will use the defaults in COCO.\n",
    "                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.\n",
    "        \"\"\"\n",
    "        self._logger = logging.getLogger(__name__)\n",
    "        self._distributed = distributed\n",
    "        self._output_dir = output_dir\n",
    "        self._use_fast_impl = use_fast_impl\n",
    "\n",
    "        if tasks is not None and isinstance(tasks, CfgNode):\n",
    "            kpt_oks_sigmas = (\n",
    "                tasks.TEST.KEYPOINT_OKS_SIGMAS if not kpt_oks_sigmas else kpt_oks_sigmas\n",
    "            )\n",
    "            self._logger.warn(\n",
    "                \"COCO Evaluator instantiated using config, this is deprecated behavior.\"\n",
    "                \" Please pass in explicit arguments instead.\"\n",
    "            )\n",
    "            self._tasks = None  # Inferring it from predictions should be better\n",
    "        else:\n",
    "            self._tasks = tasks\n",
    "\n",
    "        self._cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "        self._metadata = MetadataCatalog.get(dataset_name)\n",
    "        if not hasattr(self._metadata, \"json_file\"):\n",
    "            self._logger.info(\n",
    "                f\"'{dataset_name}' is not registered by register_coco_instances.\"\n",
    "                \" Therefore trying to convert it to COCO format ...\"\n",
    "            )\n",
    "\n",
    "            cache_path = os.path.join(output_dir, f\"{dataset_name}_coco_format.json\")\n",
    "            self._metadata.json_file = cache_path\n",
    "            convert_to_coco_json(dataset_name, cache_path)\n",
    "\n",
    "        json_file = PathManager.get_local_path(self._metadata.json_file)\n",
    "        with contextlib.redirect_stdout(io.StringIO()):\n",
    "            self._coco_api = COCO(json_file)\n",
    "\n",
    "        # Test set json files do not contain annotations (evaluation must be\n",
    "        # performed using the COCO evaluation server).\n",
    "        self._do_evaluation = \"annotations\" in self._coco_api.dataset\n",
    "        if self._do_evaluation:\n",
    "            self._kpt_oks_sigmas = kpt_oks_sigmas\n",
    "\n",
    "    def reset(self):\n",
    "        self._predictions = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n",
    "                It is a list of dict. Each dict corresponds to an image and\n",
    "                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n",
    "            outputs: the outputs of a COCO model. It is a list of dicts with key\n",
    "                \"instances\" that contains :class:Instances.\n",
    "        \"\"\"\n",
    "        for input, output in zip(inputs, outputs):\n",
    "            prediction = {\"image_id\": input[\"image_id\"]}\n",
    "\n",
    "            if \"instances\" in output:\n",
    "                instances = output[\"instances\"].to(self._cpu_device)\n",
    "                prediction[\"instances\"] = instances_to_coco_json(instances, input[\"image_id\"])\n",
    "            if \"proposals\" in output:\n",
    "                prediction[\"proposals\"] = output[\"proposals\"].to(self._cpu_device)\n",
    "            if len(prediction) > 1:\n",
    "                self._predictions.append(prediction)\n",
    "\n",
    "    def evaluate(self, img_ids=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset\n",
    "        \"\"\"\n",
    "        if self._distributed:\n",
    "            comm.synchronize()\n",
    "            predictions = comm.gather(self._predictions, dst=0)\n",
    "            predictions = list(itertools.chain(*predictions))\n",
    "\n",
    "            if not comm.is_main_process():\n",
    "                return {}\n",
    "        else:\n",
    "            predictions = self._predictions\n",
    "\n",
    "        if len(predictions) == 0:\n",
    "            self._logger.warning(\"[SayzekEvaluator] Did not receive valid predictions.\")\n",
    "            return {}\n",
    "\n",
    "        if self._output_dir:\n",
    "            PathManager.mkdirs(self._output_dir)\n",
    "            file_path = os.path.join(self._output_dir, \"instances_predictions.pth\")\n",
    "            with PathManager.open(file_path, \"wb\") as f:\n",
    "                torch.save(predictions, f)\n",
    "\n",
    "        self._results = OrderedDict()\n",
    "        if \"proposals\" in predictions[0]:\n",
    "            self._eval_box_proposals(predictions)\n",
    "        if \"instances\" in predictions[0]:\n",
    "            self._eval_predictions(predictions, img_ids=img_ids)\n",
    "        # Copy so the caller can do whatever with results\n",
    "        return copy.deepcopy(self._results)\n",
    "\n",
    "    def _tasks_from_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Get COCO API \"tasks\" (i.e. iou_type) from COCO-format predictions.\n",
    "        \"\"\"\n",
    "        tasks = {\"bbox\"}\n",
    "        for pred in predictions:\n",
    "            if \"segmentation\" in pred:\n",
    "                tasks.add(\"segm\")\n",
    "            if \"keypoints\" in pred:\n",
    "                tasks.add(\"keypoints\")\n",
    "        return sorted(tasks)\n",
    "\n",
    "    def _eval_predictions(self, predictions, img_ids=None):\n",
    "        \"\"\"\n",
    "        Evaluate predictions. Fill self._results with the metrics of the tasks.\n",
    "        \"\"\"\n",
    "        self._logger.info(\"Preparing results for COCO format ...\")\n",
    "        coco_results = list(itertools.chain(*[x[\"instances\"] for x in predictions]))\n",
    "        tasks = self._tasks or self._tasks_from_predictions(coco_results)\n",
    "\n",
    "        # unmap the category ids for COCO\n",
    "        if hasattr(self._metadata, \"thing_dataset_id_to_contiguous_id\"):\n",
    "            dataset_id_to_contiguous_id = self._metadata.thing_dataset_id_to_contiguous_id\n",
    "            all_contiguous_ids = list(dataset_id_to_contiguous_id.values())\n",
    "            num_classes = len(all_contiguous_ids)\n",
    "            assert min(all_contiguous_ids) == 0 and max(all_contiguous_ids) == num_classes - 1\n",
    "\n",
    "            reverse_id_mapping = {v: k for k, v in dataset_id_to_contiguous_id.items()}\n",
    "            for result in coco_results:\n",
    "                category_id = result[\"category_id\"]\n",
    "                assert category_id < num_classes, (\n",
    "                    f\"A prediction has class={category_id}, \"\n",
    "                    f\"but the dataset only has {num_classes} classes and \"\n",
    "                    f\"predicted class id should be in [0, {num_classes - 1}].\"\n",
    "                )\n",
    "                result[\"category_id\"] = reverse_id_mapping[category_id]\n",
    "\n",
    "        if self._output_dir:\n",
    "            file_path = os.path.join(self._output_dir, \"coco_instances_results.json\")\n",
    "            self._logger.info(\"Saving results to {}\".format(file_path))\n",
    "            with PathManager.open(file_path, \"w\") as f:\n",
    "                f.write(json.dumps(coco_results))\n",
    "                f.flush()\n",
    "\n",
    "        if not self._do_evaluation:\n",
    "            self._logger.info(\"Annotations are not available for evaluation.\")\n",
    "            return\n",
    "\n",
    "        self._logger.info(\n",
    "            \"Evaluating predictions with {} COCO API...\".format(\n",
    "                \"unofficial\" if self._use_fast_impl else \"official\"\n",
    "            )\n",
    "        )\n",
    "        for task in sorted(tasks):\n",
    "            coco_eval = (\n",
    "                _evaluate_predictions_on_coco(\n",
    "                    self._coco_api,\n",
    "                    coco_results,\n",
    "                    task,\n",
    "                    kpt_oks_sigmas=self._kpt_oks_sigmas,\n",
    "                    use_fast_impl=self._use_fast_impl,\n",
    "                    img_ids=img_ids,\n",
    "                )\n",
    "                if len(coco_results) > 0\n",
    "                else None \n",
    "            )\n",
    "\n",
    "            res = self._derive_coco_results(\n",
    "                coco_eval, task, class_names=self._metadata.get(\"thing_classes\")\n",
    "            )\n",
    "            self._results[task] = res\n",
    "\n",
    "    def _eval_box_proposals(self, predictions):\n",
    "        \"\"\"\n",
    "        Evaluate the box proposals in predictions.\n",
    "        Fill self._results with the metrics for \"box_proposals\" task.\n",
    "        \"\"\"\n",
    "        if self._output_dir:\n",
    "            # Saving generated box proposals to file.\n",
    "            # Predicted box_proposals are in XYXY_ABS mode.\n",
    "            bbox_mode = BoxMode.XYXY_ABS.value\n",
    "            ids, boxes, objectness_logits = [], [], []\n",
    "            for prediction in predictions:\n",
    "                ids.append(prediction[\"image_id\"])\n",
    "                boxes.append(prediction[\"proposals\"].proposal_boxes.tensor.numpy())\n",
    "                objectness_logits.append(prediction[\"proposals\"].objectness_logits.numpy())\n",
    "\n",
    "            proposal_data = {\n",
    "                \"boxes\": boxes,\n",
    "                \"objectness_logits\": objectness_logits,\n",
    "                \"ids\": ids,\n",
    "                \"bbox_mode\": bbox_mode,\n",
    "            }\n",
    "            with PathManager.open(os.path.join(self._output_dir, \"box_proposals.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(proposal_data, f)\n",
    "\n",
    "        if not self._do_evaluation:\n",
    "            self._logger.info(\"Annotations are not available for evaluation.\")\n",
    "            return\n",
    "\n",
    "        self._logger.info(\"Evaluating bbox proposals ...\")\n",
    "        res = {}\n",
    "        areas = {\"all\": \"\", \"small\": \"s\", \"medium\": \"m\", \"large\": \"l\"}\n",
    "        for limit in [100, 1000]:\n",
    "            for area, suffix in areas.items():\n",
    "                stats = _evaluate_box_proposals(predictions, self._coco_api, area=area, limit=limit)\n",
    "                key = \"AR{}@{:d}\".format(suffix, limit)\n",
    "                res[key] = float(stats[\"ar\"].item() * 100)\n",
    "        self._logger.info(\"Proposal metrics: \\n\" + create_small_table(res))\n",
    "        self._results[\"box_proposals\"] = res\n",
    "\n",
    "    def _derive_coco_results(self, coco_eval, iou_type, class_names=None):\n",
    "        \"\"\"\n",
    "        Derive the desired score numbers from summarized COCOeval.\n",
    "\n",
    "        Args:\n",
    "            coco_eval (None or COCOEval): None represents no predictions from model.\n",
    "            iou_type (str):\n",
    "            class_names (None or list[str]): if provided, will use it to predict\n",
    "                per-category AP.\n",
    "\n",
    "        Returns:\n",
    "            a dict of {metric name: score}\n",
    "        \"\"\"\n",
    "\n",
    "        metrics = {\n",
    "            \"bbox\": [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"],\n",
    "            \"segm\": [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"],\n",
    "            \"keypoints\": [\"AP\", \"AP50\", \"AP75\", \"APm\", \"APl\"],\n",
    "        }[iou_type]\n",
    "\n",
    "        if coco_eval is None:\n",
    "            self._logger.warn(\"No predictions from the model!\")\n",
    "            return {metric: float(\"nan\") for metric in metrics}\n",
    "\n",
    "        # the standard metrics\n",
    "        results = {\n",
    "            metric: float(coco_eval.stats[idx] * 100 if coco_eval.stats[idx] >= 0 else \"nan\")\n",
    "            for idx, metric in enumerate(metrics)\n",
    "        }\n",
    "        self._logger.info(\n",
    "            \"Evaluation results for {}: \\n\".format(iou_type) + create_small_table(results)\n",
    "        )\n",
    "        if not np.isfinite(sum(results.values())):\n",
    "            self._logger.info(\"Some metrics cannot be computed and is shown as NaN.\")\n",
    "\n",
    "        if class_names is None or len(class_names) <= 1:\n",
    "            return results\n",
    "        # Compute per-category AP\n",
    "        # from https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L222-L252 # noqa\n",
    "        precisions = coco_eval.eval[\"precision\"]\n",
    "        # precision has dims (iou, recall, cls, area range, max dets)\n",
    "        assert len(class_names) == precisions.shape[2]\n",
    "\n",
    "        results_per_category = []\n",
    "        for idx, name in enumerate(class_names):\n",
    "            # area range index 0: all area ranges\n",
    "            # max dets index -1: typically 100 per image\n",
    "            precision = precisions[:, :, idx, 0, -1]\n",
    "            precision = precision[precision > -1]\n",
    "            ap = np.mean(precision) if precision.size else float(\"nan\")\n",
    "            results_per_category.append((\"{}\".format(name), float(ap * 100)))\n",
    "\n",
    "        # tabulate it\n",
    "        N_COLS = min(6, len(results_per_category) * 2)\n",
    "        results_flatten = list(itertools.chain(*results_per_category))\n",
    "        results_2d = itertools.zip_longest(*[results_flatten[i::N_COLS] for i in range(N_COLS)])\n",
    "        table = tabulate(\n",
    "            results_2d,\n",
    "            tablefmt=\"pipe\",\n",
    "            floatfmt=\".3f\",\n",
    "            headers=[\"category\", \"AP\"] * (N_COLS // 2),\n",
    "            numalign=\"left\",\n",
    "        )\n",
    "        self._logger.info(\"Per-category {} AP: \\n\".format(iou_type) + table)\n",
    "\n",
    "        results.update({\"AP-\" + name: ap for name, ap in results_per_category})\n",
    "        return results\n",
    "\n",
    "\n",
    "def instances_to_coco_json(instances, img_id):\n",
    "    \"\"\"\n",
    "    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n",
    "\n",
    "    Args:\n",
    "        instances (Instances):\n",
    "        img_id (int): the image id\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: list of json annotations in COCO format.\n",
    "    \"\"\"\n",
    "    num_instance = len(instances)\n",
    "    if num_instance == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = instances.pred_boxes.tensor.numpy()\n",
    "    boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n",
    "    boxes = boxes.tolist()\n",
    "    scores = instances.scores.tolist()\n",
    "    classes = instances.pred_classes.tolist()\n",
    "\n",
    "    has_mask = instances.has(\"pred_masks\")\n",
    "    if has_mask:\n",
    "        # use RLE to encode the masks, because they are too large and takes memory\n",
    "        # since this evaluator stores outputs of the entire dataset\n",
    "        rles = [\n",
    "            mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n",
    "            for mask in instances.pred_masks\n",
    "        ]\n",
    "        for rle in rles:\n",
    "            # \"counts\" is an array encoded by mask_util as a byte-stream. Python3's\n",
    "            # json writer which always produces strings cannot serialize a bytestream\n",
    "            # unless you decode it. Thankfully, utf-8 works out (which is also what\n",
    "            # the pycocotools/_mask.pyx does).\n",
    "            rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
    "\n",
    "    has_keypoints = instances.has(\"pred_keypoints\")\n",
    "    if has_keypoints:\n",
    "        keypoints = instances.pred_keypoints\n",
    "\n",
    "    results = []\n",
    "    for k in range(num_instance):\n",
    "        result = {\n",
    "            \"image_id\": img_id,\n",
    "            \"category_id\": classes[k],\n",
    "            \"bbox\": boxes[k],\n",
    "            \"score\": scores[k],\n",
    "        }\n",
    "        if has_mask:\n",
    "            result[\"segmentation\"] = rles[k]\n",
    "        if has_keypoints:\n",
    "            # In COCO annotations,\n",
    "            # keypoints coordinates are pixel indices.\n",
    "            # However our predictions are floating point coordinates.\n",
    "            # Therefore we subtract 0.5 to be consistent with the annotation format.\n",
    "            # This is the inverse of data loading logic in datasets/coco.py.\n",
    "            keypoints[k][:, :2] -= 0.5\n",
    "            result[\"keypoints\"] = keypoints[k].flatten().tolist()\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "# inspired from Detectron:\n",
    "# https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L255 # noqa\n",
    "def _evaluate_box_proposals(dataset_predictions, coco_api, thresholds=None, area=\"all\", limit=None):\n",
    "    \"\"\"\n",
    "    Evaluate detection proposal recall metrics. This function is a much\n",
    "    faster alternative to the official COCO API recall evaluation code. However,\n",
    "    it produces slightly different results.\n",
    "    \"\"\"\n",
    "    # Record max overlap value for each gt box\n",
    "    # Return vector of overlap values\n",
    "    areas = {\n",
    "        \"all\": 0,\n",
    "        \"small\": 1,\n",
    "        \"medium\": 2,\n",
    "        \"large\": 3,\n",
    "        \"96-128\": 4,\n",
    "        \"128-256\": 5,\n",
    "        \"256-512\": 6,\n",
    "        \"512-inf\": 7,\n",
    "    }\n",
    "    area_ranges = [\n",
    "        [0 ** 2, 1e5 ** 2],  # all\n",
    "        [0 ** 2, 32 ** 2],  # small\n",
    "        [32 ** 2, 96 ** 2],  # medium\n",
    "        [96 ** 2, 1e5 ** 2],  # large\n",
    "        [96 ** 2, 128 ** 2],  # 96-128\n",
    "        [128 ** 2, 256 ** 2],  # 128-256\n",
    "        [256 ** 2, 512 ** 2],  # 256-512\n",
    "        [512 ** 2, 1e5 ** 2],\n",
    "    ]  # 512-inf\n",
    "    assert area in areas, \"Unknown area range: {}\".format(area)\n",
    "    area_range = area_ranges[areas[area]]\n",
    "    gt_overlaps = []\n",
    "    num_pos = 0\n",
    "\n",
    "    for prediction_dict in dataset_predictions:\n",
    "        predictions = prediction_dict[\"proposals\"]\n",
    "\n",
    "        # sort predictions in descending order\n",
    "        # TODO maybe remove this and make it explicit in the documentation\n",
    "        inds = predictions.objectness_logits.sort(descending=True)[1]\n",
    "        predictions = predictions[inds]\n",
    "\n",
    "        ann_ids = coco_api.getAnnIds(imgIds=prediction_dict[\"image_id\"])\n",
    "        anno = coco_api.loadAnns(ann_ids)\n",
    "        gt_boxes = [\n",
    "            BoxMode.convert(obj[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "            for obj in anno\n",
    "            if obj[\"iscrowd\"] == 0\n",
    "        ]\n",
    "        gt_boxes = torch.as_tensor(gt_boxes).reshape(-1, 4)  # guard against no boxes\n",
    "        gt_boxes = Boxes(gt_boxes)\n",
    "        gt_areas = torch.as_tensor([obj[\"area\"] for obj in anno if obj[\"iscrowd\"] == 0])\n",
    "\n",
    "        if len(gt_boxes) == 0 or len(predictions) == 0:\n",
    "            continue\n",
    "\n",
    "        valid_gt_inds = (gt_areas >= area_range[0]) & (gt_areas <= area_range[1])\n",
    "        gt_boxes = gt_boxes[valid_gt_inds]\n",
    "\n",
    "        num_pos += len(gt_boxes)\n",
    "\n",
    "        if len(gt_boxes) == 0:\n",
    "            continue\n",
    "\n",
    "        if limit is not None and len(predictions) > limit:\n",
    "            predictions = predictions[:limit]\n",
    "\n",
    "        overlaps = pairwise_iou(predictions.proposal_boxes, gt_boxes)\n",
    "\n",
    "        _gt_overlaps = torch.zeros(len(gt_boxes))\n",
    "        for j in range(min(len(predictions), len(gt_boxes))):\n",
    "            # find which proposal box maximally covers each gt box\n",
    "            # and get the iou amount of coverage for each gt box\n",
    "            max_overlaps, argmax_overlaps = overlaps.max(dim=0)\n",
    "\n",
    "            # find which gt box is 'best' covered (i.e. 'best' = most iou)\n",
    "            gt_ovr, gt_ind = max_overlaps.max(dim=0)\n",
    "            assert gt_ovr >= 0\n",
    "            # find the proposal box that covers the best covered gt box\n",
    "            box_ind = argmax_overlaps[gt_ind]\n",
    "            # record the iou coverage of this gt box\n",
    "            _gt_overlaps[j] = overlaps[box_ind, gt_ind]\n",
    "            assert _gt_overlaps[j] == gt_ovr\n",
    "            # mark the proposal box and the gt box as used\n",
    "            overlaps[box_ind, :] = -1\n",
    "            overlaps[:, gt_ind] = -1\n",
    "\n",
    "        # append recorded iou coverage level\n",
    "        gt_overlaps.append(_gt_overlaps)\n",
    "    gt_overlaps = (\n",
    "        torch.cat(gt_overlaps, dim=0) if len(gt_overlaps) else torch.zeros(0, dtype=torch.float32)\n",
    "    )\n",
    "    gt_overlaps, _ = torch.sort(gt_overlaps)\n",
    "\n",
    "    if thresholds is None:\n",
    "        step = 0.05\n",
    "        thresholds = torch.arange(0.5, 0.95 + 1e-5, step, dtype=torch.float32)\n",
    "    recalls = torch.zeros_like(thresholds)\n",
    "    # compute recall for each iou threshold\n",
    "    for i, t in enumerate(thresholds):\n",
    "        recalls[i] = (gt_overlaps >= t).float().sum() / float(num_pos)\n",
    "    ar = recalls.mean()\n",
    "    return {\n",
    "        \"ar\": ar,\n",
    "        \"recalls\": recalls,\n",
    "        \"thresholds\": thresholds,\n",
    "        \"gt_overlaps\": gt_overlaps,\n",
    "        \"num_pos\": num_pos,\n",
    "    }\n",
    "\n",
    "\n",
    "def _evaluate_predictions_on_coco(\n",
    "    coco_gt, coco_results, iou_type, kpt_oks_sigmas=None, use_fast_impl=True, img_ids=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the coco results using COCOEval API.\n",
    "    \"\"\"\n",
    "    assert len(coco_results) > 0\n",
    "\n",
    "    if iou_type == \"segm\":\n",
    "        coco_results = copy.deepcopy(coco_results)\n",
    "        # When evaluating mask AP, if the results contain bbox, cocoapi will\n",
    "        # use the box area as the area of the instance, instead of the mask area.\n",
    "        # This leads to a different definition of small/medium/large.\n",
    "        # We remove the bbox field to let mask AP use mask area.\n",
    "        for c in coco_results:\n",
    "            c.pop(\"bbox\", None)\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(coco_results)\n",
    "    coco_eval = (COCOeval_opt if use_fast_impl else COCOeval)(coco_gt, coco_dt, iou_type)\n",
    "\n",
    "    if img_ids is not None:\n",
    "        coco_eval.params.imgIds = img_ids\n",
    "\n",
    "    if iou_type == \"keypoints\":\n",
    "        # Use the COCO default keypoint OKS sigmas unless overrides are specified\n",
    "        if kpt_oks_sigmas:\n",
    "            assert hasattr(coco_eval.params, \"kpt_oks_sigmas\"), \"pycocotools is too old!\"\n",
    "            coco_eval.params.kpt_oks_sigmas = np.array(kpt_oks_sigmas)\n",
    "        # COCOAPI requires every detection and every gt to have keypoints, so\n",
    "        # we just take the first entry from both\n",
    "        num_keypoints_dt = len(coco_results[0][\"keypoints\"]) // 3\n",
    "        num_keypoints_gt = len(next(iter(coco_gt.anns.values()))[\"keypoints\"]) // 3\n",
    "        num_keypoints_oks = len(coco_eval.params.kpt_oks_sigmas)\n",
    "        assert num_keypoints_oks == num_keypoints_dt == num_keypoints_gt, (\n",
    "            f\"[SayzekEvaluator] Prediction contain {num_keypoints_dt} keypoints. \"\n",
    "            f\"Ground truth contains {num_keypoints_gt} keypoints. \"\n",
    "            f\"The length of cfg.TEST.KEYPOINT_OKS_SIGMAS is {num_keypoints_oks}. \"\n",
    "            \"They have to agree with each other. For meaning of OKS, please refer to \"\n",
    "            \"http://cocodataset.org/#keypoints-eval.\"\n",
    "        )\n",
    "\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    return coco_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Evaluation Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.194040Z",
     "iopub.status.busy": "2024-10-15T11:42:41.193740Z",
     "iopub.status.idle": "2024-10-15T11:42:41.273520Z",
     "shell.execute_reply": "2024-10-15T11:42:41.272603Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.194007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To calculate & record validation loss\n",
    "\n",
    "Original code from https://medium.com/@apofeniaco/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
    "by @apofeniaco\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "\n",
    "    def _do_loss_eval(self):\n",
    "        # Keep the model in training mode to compute losses\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for idx, inputs in enumerate(self._data_loader):\n",
    "                # Compute the loss without gradients\n",
    "                loss_dict = self._model(inputs)\n",
    "                # Sum all losses into a single scalar\n",
    "                total_loss = sum(loss_dict.values()).item()\n",
    "                losses.append(total_loss)\n",
    "        # Compute the mean validation loss\n",
    "        mean_loss = np.mean(losses)\n",
    "        # Record the validation loss in the trainer's storage\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        return mean_loss\n",
    "\n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            mean_loss = self._do_loss_eval()\n",
    "            print(f\"Validation Loss: {mean_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.275537Z",
     "iopub.status.busy": "2024-10-15T11:42:41.275110Z",
     "iopub.status.idle": "2024-10-15T11:42:41.286330Z",
     "shell.execute_reply": "2024-10-15T11:42:41.285486Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.275493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TrainerStopException(Exception):\n",
    "    \"\"\"Custom exception to stop training.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class EarlyStoppingHook(HookBase):\n",
    "    def __init__(self, patience: int, eval_period: int, trainer):\n",
    "        self.patience = patience\n",
    "        self.eval_period = eval_period\n",
    "        self.trainer = trainer\n",
    "        self.best_loss = float('inf')\n",
    "        self.iter_without_improvement = 0\n",
    "        self.best_iter = 0  \n",
    "        self.best_model_weights = None \n",
    "\n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "\n",
    "        # Only check for early stopping after an evaluation period\n",
    "        if next_iter % self.eval_period == 0 and next_iter > 0:\n",
    "            # Get the current validation loss\n",
    "            validation_loss = self.trainer.storage.history(\"validation_loss\").latest()\n",
    "\n",
    "            # Check if validation loss has improved\n",
    "            if validation_loss < self.best_loss:\n",
    "                self.best_loss = validation_loss\n",
    "                self.iter_without_improvement = 0\n",
    "                self.best_iter = self.trainer.iter\n",
    "                self.best_model_weights = copy.deepcopy(self.trainer.model.state_dict())  # En iyi modeli sakla\n",
    "                print(f\"Validation loss improved to {validation_loss:.4f} at iter {self.best_iter}\")\n",
    "            else:\n",
    "                self.iter_without_improvement += 1\n",
    "                print(f\"No improvement in validation loss for {self.iter_without_improvement} evaluations.\")\n",
    "\n",
    "            # Check if patience limit is reached\n",
    "            if self.iter_without_improvement >= self.patience:\n",
    "                print(f\"Early stopping at iteration {self.trainer.iter} due to no improvement in validation loss.\")\n",
    "                \n",
    "                final_model_path = os.path.join(self.trainer.cfg.OUTPUT_DIR, \"best_model.pth\")\n",
    "                torch.save(self.best_model_weights, final_model_path)\n",
    "                print(f\"Best model from iter {self.best_iter} saved to {final_model_path}\")\n",
    "\n",
    "                raise TrainerStopException()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Parameters for Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.288008Z",
     "iopub.status.busy": "2024-10-15T11:42:41.287543Z",
     "iopub.status.idle": "2024-10-15T11:42:41.582613Z",
     "shell.execute_reply": "2024-10-15T11:42:41.581730Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.287965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import dataclasses\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from distutils.util import strtobool\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer, launch\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.584354Z",
     "iopub.status.busy": "2024-10-15T11:42:41.583962Z",
     "iopub.status.idle": "2024-10-15T11:42:41.593948Z",
     "shell.execute_reply": "2024-10-15T11:42:41.593003Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.584311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- flags ---\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Flags:\n",
    "    # General\n",
    "    debug: bool = True\n",
    "    outdir: str = \"results/det\"\n",
    "\n",
    "    # Data config\n",
    "    imgdir_name: str = \"sayzek-datathon-data\"\n",
    "    split_mode: str = \"all_train\"  # all_train or valid20\n",
    "    seed: int = 111\n",
    "    train_data_type: str = \"original\"  # original or wbf\n",
    "    valid_size: float = 0.16  # Proportion of data to use for validation\n",
    "\n",
    "    # Training config\n",
    "    iter: int = 10000\n",
    "    ims_per_batch: int = 2  # images per batch, this corresponds to \"total batch size\"\n",
    "    num_workers: int = 4\n",
    "    lr_scheduler_name: str = \"WarmupMultiStepLR\"  # WarmupMultiStepLR (default) or WarmupCosineLR\n",
    "    base_lr: float = 0.00025\n",
    "    roi_batch_size_per_image: int = 512\n",
    "    #eval_period: int = 10000\n",
    "    aug_kwargs: Dict = field(default_factory=lambda: {})\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Flags\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.595285Z",
     "iopub.status.busy": "2024-10-15T11:42:41.595005Z",
     "iopub.status.idle": "2024-10-15T11:42:41.604739Z",
     "shell.execute_reply": "2024-10-15T11:42:41.603868Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.595253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "flags_dict = {\n",
    "    \"debug\": False,\n",
    "    \"outdir\": \"results/v1\", \n",
    "    \"imgdir_name\": \"sayzek-datathon-data\",\n",
    "    \"split_mode\": \"valid16\",\n",
    "    \"iter\": 2900,\n",
    "    \"roi_batch_size_per_image\": 512,\n",
    "    \"ims_per_batch\": 2, \n",
    "    \"lr_scheduler_name\": \"WarmupCosineLR\",\n",
    "    \"base_lr\": 0.0020494837715941665,\n",
    "    \"num_workers\": 4,\n",
    "    \"valid_size\": 0.16,\n",
    "    \"aug_kwargs\": {\n",
    "        \"HorizontalFlip\": {\"p\": 0.5},\n",
    "        \"ShiftScaleRotate\": {\"scale_limit\": 0.15, \"rotate_limit\": 10, \"p\": 0.5},\n",
    "        \"RandomBrightnessContrast\": {\"p\": 0.5}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.606008Z",
     "iopub.status.busy": "2024-10-15T11:42:41.605736Z",
     "iopub.status.idle": "2024-10-15T11:42:41.644786Z",
     "shell.execute_reply": "2024-10-15T11:42:41.643903Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.605978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.4.0\n",
      "flags Flags(debug=False, outdir='results/v1', imgdir_name='sayzek-datathon-data', split_mode='valid16', seed=111, train_data_type='original', valid_size=0.16, iter=2900, ims_per_batch=2, num_workers=4, lr_scheduler_name='WarmupCosineLR', base_lr=0.0020494837715941665, roi_batch_size_per_image=512, aug_kwargs={'HorizontalFlip': {'p': 0.5}, 'ShiftScaleRotate': {'scale_limit': 0.15, 'rotate_limit': 10, 'p': 0.5}, 'RandomBrightnessContrast': {'p': 0.5}})\n"
     ]
    }
   ],
   "source": [
    "# args = parse()\n",
    "print(\"torch\", torch.__version__)\n",
    "flags = Flags().update(flags_dict)\n",
    "print(\"flags\", flags)\n",
    "debug = flags.debug\n",
    "outdir = Path(flags.outdir)\n",
    "os.makedirs(str(outdir), exist_ok=True)\n",
    "flags_dict = dataclasses.asdict(flags)\n",
    "save_yaml(outdir / \"flags.yaml\", flags_dict)\n",
    "\n",
    "# --- Read data ---\n",
    "inputdir = Path(\"/kaggle/input\")\n",
    "datadir = inputdir / \"sayzek-datathon-data\"\n",
    "imgdir = inputdir / flags.imgdir_name\n",
    "\n",
    "# Read in the data CSV files\n",
    "train_df = pd.read_csv(datadir / \"train_dataset_detectron2.csv\")\n",
    "train = train_df  # alias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Stratified Data Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.646076Z",
     "iopub.status.busy": "2024-10-15T11:42:41.645814Z",
     "iopub.status.idle": "2024-10-15T11:42:41.711527Z",
     "shell.execute_reply": "2024-10-15T11:42:41.710583Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.646047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stratified split for valid16...\n"
     ]
    }
   ],
   "source": [
    "train_data_type = flags.train_data_type\n",
    "\n",
    "split_mode = flags.split_mode\n",
    "if split_mode == \"all_train\":\n",
    "    DatasetCatalog.register(\n",
    "        \"sayzek_train\",  \n",
    "        lambda: get_custom_dicts(\n",
    "            imgdir, train_df, train_data_type, debug=debug \n",
    "        ),\n",
    "    )\n",
    "    MetadataCatalog.get(\"sayzek_train\").set(thing_classes=thing_classes)  \n",
    "\n",
    "elif split_mode == \"valid16\":\n",
    "    print(\"Performing stratified split for valid16...\")\n",
    "    # Read 'train_meta' and apply 'debug' trimming\n",
    "    train_meta = pd.read_csv(imgdir / \"train_meta.csv\")\n",
    "    if debug:\n",
    "        train_meta = train_meta.iloc[:200]  # Reduce data size in debug mode\n",
    "    image_ids = train_meta['image_id'].tolist()\n",
    "\n",
    "    # Filter 'train_df' to only include images in 'train_meta'\n",
    "    train_df_filtered = train_df[train_df['image_id'].isin(image_ids)]\n",
    "\n",
    "    # Prepare class labels per image\n",
    "    class_ids = train_df_filtered[['image_id', 'class_id']]\n",
    "\n",
    "    # One-hot encode 'class_id'\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoded = encoder.fit_transform(class_ids[['class_id']])\n",
    "\n",
    "    # Get class names\n",
    "    class_names = ['class_' + str(int(cls)) for cls in encoder.categories_[0]]\n",
    "\n",
    "    # Create DataFrame and add 'image_id'\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=class_names)\n",
    "    one_hot_df['image_id'] = class_ids['image_id'].values\n",
    "\n",
    "    # Group by 'image_id'\n",
    "    y = one_hot_df.groupby('image_id')[class_names].max().reset_index()\n",
    "    X = y[['image_id']]\n",
    "\n",
    "    # Prepare MultilabelStratifiedShuffleSplit using flags.valid_size\n",
    "    mskf = MultilabelStratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=flags.valid_size, random_state=flags.seed\n",
    "    )\n",
    "\n",
    "    for train_index, valid_index in mskf.split(X, y[class_names]): \n",
    "        train_image_ids = X.iloc[train_index]['image_id'].values\n",
    "        valid_image_ids = X.iloc[valid_index]['image_id'].values\n",
    "\n",
    "    # Register datasets\n",
    "    DatasetCatalog.register(\n",
    "        \"sayzek_train\",\n",
    "        lambda: get_custom_dicts(\n",
    "            imgdir,\n",
    "            train_df,\n",
    "            train_data_type,\n",
    "            debug=debug,\n",
    "            target_image_ids=train_image_ids,\n",
    "        ),\n",
    "    )\n",
    "    MetadataCatalog.get(\"sayzek_train\").set(thing_classes=thing_classes)\n",
    "\n",
    "    DatasetCatalog.register(\n",
    "        \"sayzek_valid\",\n",
    "        lambda: get_custom_dicts(\n",
    "            imgdir,\n",
    "            train_df,\n",
    "            train_data_type,\n",
    "            debug=debug,\n",
    "            target_image_ids=valid_image_ids,\n",
    "        ),\n",
    "    )\n",
    "    MetadataCatalog.get(\"sayzek_valid\").set(thing_classes=thing_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset For Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:41.713593Z",
     "iopub.status.busy": "2024-10-15T11:42:41.713079Z",
     "iopub.status.idle": "2024-10-15T11:42:43.447768Z",
     "shell.execute_reply": "2024-10-15T11:42:43.446907Z",
     "shell.execute_reply.started": "2024-10-15T11:42:41.713544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "Image shape: (512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:01<00:00, 262.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "train_dataset = DatasetCatalog.get(\"sayzek_train\")\n",
    "\n",
    "class_counts = {i: 0 for i in range(len(thing_classes))}\n",
    "for record in train_dataset:\n",
    "    for anno in record[\"annotations\"]:\n",
    "        class_counts[anno[\"category_id\"]] += 1\n",
    "\n",
    "class_weights = [1.0 / (class_counts[i] + 1e-6) for i in range(len(thing_classes))]\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        dataset_dicts = DatasetCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "        class_frequencies = get_class_frequencies(dataset_dicts, len(thing_classes))\n",
    "        repeat_factors = get_repeat_factors(dataset_dicts, class_frequencies)\n",
    "        sampler = RepeatFactorTrainingSampler(repeat_factors)\n",
    "        \n",
    "        return build_detection_train_loader(\n",
    "            cfg, mapper=AlbumentationsMapper(cfg, is_train=True), sampler=sampler\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        return build_detection_test_loader(\n",
    "            cfg, dataset_name, mapper=AlbumentationsMapper(cfg, is_train=False)\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        \n",
    "        # Access cfg using self.cfg\n",
    "        cfg = self.cfg\n",
    "        \n",
    "        # Loss evaluation hook\n",
    "        loss_eval_hook = LossEvalHook(\n",
    "            cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            self.build_test_loader(cfg, cfg.DATASETS.TEST[0]),\n",
    "        )\n",
    "        hooks.insert(-1, loss_eval_hook)\n",
    "        \n",
    "        early_stopping_hook = EarlyStoppingHook(patience=5, eval_period=cfg.TEST.EVAL_PERIOD, trainer=self)\n",
    "        hooks.append(early_stopping_hook)\n",
    "        \n",
    "        return hooks\n",
    "\n",
    "    def train(self):\n",
    "        try:\n",
    "            super().train() \n",
    "        except TrainerStopException:\n",
    "            print(\"Training stopped due to early stopping.\")\n",
    "            \n",
    "            final_model_path = os.path.join(self.cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "            torch.save(self.model.state_dict(), final_model_path)\n",
    "            print(f\"Model weights saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:43.449475Z",
     "iopub.status.busy": "2024-10-15T11:42:43.449087Z",
     "iopub.status.idle": "2024-10-15T11:42:43.465166Z",
     "shell.execute_reply": "2024-10-15T11:42:43.464277Z",
     "shell.execute_reply.started": "2024-10-15T11:42:43.449432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = get_custom_dicts(imgdir, train, debug=debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with RetinaNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:43.466655Z",
     "iopub.status.busy": "2024-10-15T11:42:43.466341Z",
     "iopub.status.idle": "2024-10-15T11:42:43.506755Z",
     "shell.execute_reply": "2024-10-15T11:42:43.505876Z",
     "shell.execute_reply.started": "2024-10-15T11:42:43.466601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.OUTPUT_DIR ./output -> results/v1\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config.config import CfgNode as CN\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.aug_kwargs = CN(flags.aug_kwargs)  # pass aug_kwargs to cfg\n",
    "\n",
    "original_output_dir = cfg.OUTPUT_DIR\n",
    "cfg.OUTPUT_DIR = str(outdir)\n",
    "print(f\"cfg.OUTPUT_DIR {original_output_dir} -> {cfg.OUTPUT_DIR}\")\n",
    "\n",
    "config_name = \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
    "cfg.DATASETS.TRAIN = (\"sayzek_train\",)\n",
    "if split_mode == \"all_train\":\n",
    "    cfg.DATASETS.TEST = ()\n",
    "else:\n",
    "    cfg.DATASETS.TEST = (\"sayzek_valid\",)\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = flags.ims_per_batch\n",
    "train_dataset = DatasetCatalog.get(\"sayzek_train\")  \n",
    "num_train_images = len(train_dataset)\n",
    "cfg.TEST.EVAL_PERIOD = int(num_train_images / cfg.SOLVER.IMS_PER_BATCH) \n",
    "cfg.DATALOADER.NUM_WORKERS = flags.num_workers\n",
    "# Let training initialize from model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = flags.lr_scheduler_name\n",
    "cfg.SOLVER.BASE_LR = flags.base_lr  \n",
    "cfg.SOLVER.MAX_ITER = flags.iter\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 100000  # Small value=Frequent save need a lot of storage.\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = flags.roi_batch_size_per_image\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = len(thing_classes)\n",
    "cfg.MODEL.RETINANET.FOCAL_LOSS_GAMMA = 2.1991655897499314 \n",
    "cfg.MODEL.RETINANET.FOCAL_LOSS_ALPHA = 0.1546578114111799  \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:42:43.508645Z",
     "iopub.status.busy": "2024-10-15T11:42:43.508028Z",
     "iopub.status.idle": "2024-10-15T11:51:59.105193Z",
     "shell.execute_reply": "2024-10-15T11:51:59.104035Z",
     "shell.execute_reply.started": "2024-10-15T11:42:43.508603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:42:44 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "[AlbumentationsMapper] Augmentations used in training: Compose([\n",
      "  HorizontalFlip(p=0.5),\n",
      "  ShiftScaleRotate(p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.15000000000000002, 0.1499999999999999), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=0.0, mask_value=0.0, rotate_method='largest_box'),\n",
      "  RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:42:44 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 364 images left.\n",
      "\u001b[32m[10/15 11:42:44 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|    bina    | 5235         | yol_kesisimi | 398          | futbol_sahası | 18           |\n",
      "|    silo    | 67           |              |              |               |              |\n",
      "|   total    | 5718         |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[10/15 11:42:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:42:44 d2.data.common]: \u001b[0mSerializing 364 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:42:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.38 MiB\n",
      "\u001b[32m[10/15 11:42:44 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:42:44 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|    bina    | 982          | yol_kesisimi | 70           | futbol_sahası | 3            |\n",
      "|    silo    | 8            |              |              |               |              |\n",
      "|   total    | 1063         |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[10/15 11:42:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:42:44 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:42:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/15 11:42:44 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "model_final_5bd44e.pkl: 152MB [00:00, 242MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:42:45 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:513: UserWarning:\n",
      "\n",
      "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:42:52 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 19  total_loss: 1.828  loss_cls: 0.9255  loss_box_reg: 0.9154    time: 0.2143  last_time: 0.1385  data_time: 0.0199  last_data_time: 0.0076   lr: 3.0601e-05  max_mem: 1792M\n",
      "\u001b[32m[10/15 11:43:07 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 39  total_loss: 1.106  loss_cls: 0.602  loss_box_reg: 0.4711    time: 0.1897  last_time: 0.1351  data_time: 0.0102  last_data_time: 0.0063   lr: 6.0654e-05  max_mem: 1793M\n",
      "\u001b[32m[10/15 11:43:10 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 59  total_loss: 0.9759  loss_cls: 0.5947  loss_box_reg: 0.4011    time: 0.1783  last_time: 0.1632  data_time: 0.0094  last_data_time: 0.0154   lr: 9.0708e-05  max_mem: 1794M\n",
      "\u001b[32m[10/15 11:43:13 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 79  total_loss: 0.8802  loss_cls: 0.4926  loss_box_reg: 0.4187    time: 0.1711  last_time: 0.1765  data_time: 0.0096  last_data_time: 0.0146   lr: 0.00012076  max_mem: 1794M\n",
      "\u001b[32m[10/15 11:43:16 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 99  total_loss: 0.8448  loss_cls: 0.4248  loss_box_reg: 0.4102    time: 0.1666  last_time: 0.1767  data_time: 0.0099  last_data_time: 0.0114   lr: 0.00015082  max_mem: 1794M\n",
      "\u001b[32m[10/15 11:43:19 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 119  total_loss: 0.6782  loss_cls: 0.3548  loss_box_reg: 0.3433    time: 0.1634  last_time: 0.1364  data_time: 0.0086  last_data_time: 0.0103   lr: 0.00018087  max_mem: 1794M\n",
      "\u001b[32m[10/15 11:43:22 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 139  total_loss: 0.7647  loss_cls: 0.3614  loss_box_reg: 0.4103    time: 0.1600  last_time: 0.1373  data_time: 0.0085  last_data_time: 0.0058   lr: 0.00021092  max_mem: 1794M\n",
      "\u001b[32m[10/15 11:43:25 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 159  total_loss: 0.7502  loss_cls: 0.3401  loss_box_reg: 0.4188    time: 0.1587  last_time: 0.1393  data_time: 0.0089  last_data_time: 0.0105   lr: 0.00024098  max_mem: 1794M\n",
      "\u001b[32m[10/15 11:43:28 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 179  total_loss: 0.6774  loss_cls: 0.2788  loss_box_reg: 0.4028    time: 0.1572  last_time: 0.1842  data_time: 0.0099  last_data_time: 0.0091   lr: 0.00027103  max_mem: 1794M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:43:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:43:28 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:43:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:43:28 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:43:28 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'sayzek_valid' to COCO format ...\n",
      "\u001b[32m[10/15 11:43:28 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'sayzek_valid' to COCO format ...)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:43:28 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:43:29 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 71, #annotations: 1063\n",
      "\u001b[32m[10/15 11:43:29 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at 'results/v1/inference/sayzek_valid_coco_format.json' ...\n",
      "\u001b[32m[10/15 11:43:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0020 s/iter. Inference: 0.0346 s/iter. Eval: 0.0004 s/iter. Total: 0.0370 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:43:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.522650 (0.038222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.034055 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.833 | 9.313  | 4.685  | 1.800 | 7.241 | 8.565 |\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 19.330 | yol_kesisimi | 0.000 | futbol_sahası | 0.000 |\n",
      "| silo       | 0.000  |              |       |               |       |\n",
      "\u001b[32m[10/15 11:43:32 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:43:32 d2.evaluation.testing]: \u001b[0mcopypaste: 4.8326,9.3127,4.6845,1.8004,7.2406,8.5654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6009594453892237\n",
      "Validation loss improved to 0.6010 at iter 181\n",
      "\u001b[32m[10/15 11:43:38 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 199  total_loss: 0.7749  loss_cls: 0.3225  loss_box_reg: 0.4524  validation_loss: 0.601    time: 0.1567  last_time: 0.1636  data_time: 0.0118  last_data_time: 0.0089   lr: 0.00030108  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:41 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 219  total_loss: 0.6627  loss_cls: 0.287  loss_box_reg: 0.3847  validation_loss: 0.601    time: 0.1571  last_time: 0.1256  data_time: 0.0100  last_data_time: 0.0069   lr: 0.00033114  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:44 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 239  total_loss: 0.6219  loss_cls: 0.2642  loss_box_reg: 0.3764  validation_loss: 0.601    time: 0.1566  last_time: 0.1762  data_time: 0.0131  last_data_time: 0.0187   lr: 0.00036119  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:47 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 259  total_loss: 0.5495  loss_cls: 0.2417  loss_box_reg: 0.3106  validation_loss: 0.601    time: 0.1556  last_time: 0.1782  data_time: 0.0093  last_data_time: 0.0053   lr: 0.00039125  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:50 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 279  total_loss: 0.6259  loss_cls: 0.2386  loss_box_reg: 0.3802  validation_loss: 0.601    time: 0.1554  last_time: 0.1369  data_time: 0.0142  last_data_time: 0.0094   lr: 0.0004213  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:53 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 299  total_loss: 0.5673  loss_cls: 0.2221  loss_box_reg: 0.3295  validation_loss: 0.601    time: 0.1550  last_time: 0.1637  data_time: 0.0104  last_data_time: 0.0204   lr: 0.00045135  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:56 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 319  total_loss: 0.6186  loss_cls: 0.2413  loss_box_reg: 0.3637  validation_loss: 0.601    time: 0.1553  last_time: 0.1579  data_time: 0.0136  last_data_time: 0.0138   lr: 0.00048141  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:43:59 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 339  total_loss: 0.5317  loss_cls: 0.2328  loss_box_reg: 0.3168  validation_loss: 0.601    time: 0.1553  last_time: 0.2295  data_time: 0.0096  last_data_time: 0.0311   lr: 0.00051146  max_mem: 1937M\n",
      "\u001b[32m[10/15 11:44:02 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 359  total_loss: 0.5226  loss_cls: 0.2017  loss_box_reg: 0.3002  validation_loss: 0.601    time: 0.1549  last_time: 0.1603  data_time: 0.0096  last_data_time: 0.0101   lr: 0.00054152  max_mem: 1937M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:44:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:44:03 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:44:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:44:03 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:44:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0021 s/iter. Inference: 0.0326 s/iter. Eval: 0.0004 s/iter. Total: 0.0351 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:44:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.432870 (0.036862 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.032789 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 10.379 | 17.893 | 11.017 | 5.715 | 20.333 | 12.958 |\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 31.190 | yol_kesisimi | 0.029 | futbol_sahası | 0.000 |\n",
      "| silo       | 10.297 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:44:06 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:44:06 d2.evaluation.testing]: \u001b[0mcopypaste: 10.3790,17.8935,11.0167,5.7147,20.3328,12.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5154332904748513\n",
      "Validation loss improved to 0.5154 at iter 363\n",
      "\u001b[32m[10/15 11:44:11 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 379  total_loss: 0.488  loss_cls: 0.1971  loss_box_reg: 0.2922  validation_loss: 0.5154    time: 0.1554  last_time: 0.1464  data_time: 0.0142  last_data_time: 0.0173   lr: 0.00057157  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:15 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 399  total_loss: 0.4707  loss_cls: 0.1914  loss_box_reg: 0.2885  validation_loss: 0.5154    time: 0.1554  last_time: 0.1486  data_time: 0.0098  last_data_time: 0.0246   lr: 0.00060162  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:17 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 419  total_loss: 0.5719  loss_cls: 0.2248  loss_box_reg: 0.3492  validation_loss: 0.5154    time: 0.1550  last_time: 0.1548  data_time: 0.0099  last_data_time: 0.0070   lr: 0.00063168  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:20 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 439  total_loss: 0.515  loss_cls: 0.1926  loss_box_reg: 0.3103  validation_loss: 0.5154    time: 0.1548  last_time: 0.1668  data_time: 0.0112  last_data_time: 0.0292   lr: 0.00066173  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:24 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 459  total_loss: 0.5271  loss_cls: 0.1935  loss_box_reg: 0.3274  validation_loss: 0.5154    time: 0.1549  last_time: 0.1648  data_time: 0.0110  last_data_time: 0.0106   lr: 0.00069178  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:27 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 479  total_loss: 0.5878  loss_cls: 0.1962  loss_box_reg: 0.3464  validation_loss: 0.5154    time: 0.1550  last_time: 0.1571  data_time: 0.0118  last_data_time: 0.0120   lr: 0.00072184  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:30 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 499  total_loss: 0.3887  loss_cls: 0.1651  loss_box_reg: 0.2315  validation_loss: 0.5154    time: 0.1549  last_time: 0.1560  data_time: 0.0105  last_data_time: 0.0123   lr: 0.00075189  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:33 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 519  total_loss: 0.544  loss_cls: 0.202  loss_box_reg: 0.3243  validation_loss: 0.5154    time: 0.1546  last_time: 0.1282  data_time: 0.0117  last_data_time: 0.0095   lr: 0.00078195  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:36 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 539  total_loss: 0.5495  loss_cls: 0.2  loss_box_reg: 0.3381  validation_loss: 0.5154    time: 0.1543  last_time: 0.1703  data_time: 0.0102  last_data_time: 0.0126   lr: 0.000812  max_mem: 1938M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:44:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:44:37 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:44:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:44:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:44:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0019 s/iter. Inference: 0.0344 s/iter. Eval: 0.0005 s/iter. Total: 0.0367 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:44:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.538503 (0.038462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.033678 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.340 | 20.001 | 12.308 | 7.438 | 17.895 | 22.079 |\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 36.756 | yol_kesisimi | 3.270 | futbol_sahası | 0.000 |\n",
      "| silo       | 5.332  |              |       |               |       |\n",
      "\u001b[32m[10/15 11:44:41 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:44:41 d2.evaluation.testing]: \u001b[0mcopypaste: 11.3396,20.0013,12.3078,7.4377,17.8948,22.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4565783763225649\n",
      "Validation loss improved to 0.4566 at iter 545\n",
      "\u001b[32m[10/15 11:44:46 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 559  total_loss: 0.5875  loss_cls: 0.2101  loss_box_reg: 0.3659  validation_loss: 0.4566    time: 0.1537  last_time: 0.1250  data_time: 0.0097  last_data_time: 0.0054   lr: 0.00084205  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:49 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 579  total_loss: 0.4683  loss_cls: 0.1792  loss_box_reg: 0.2909  validation_loss: 0.4566    time: 0.1537  last_time: 0.1306  data_time: 0.0101  last_data_time: 0.0060   lr: 0.00087211  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:52 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 599  total_loss: 0.5084  loss_cls: 0.1787  loss_box_reg: 0.3271  validation_loss: 0.4566    time: 0.1534  last_time: 0.1403  data_time: 0.0103  last_data_time: 0.0066   lr: 0.00090216  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:55 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 619  total_loss: 0.4192  loss_cls: 0.1565  loss_box_reg: 0.2531  validation_loss: 0.4566    time: 0.1534  last_time: 0.1476  data_time: 0.0113  last_data_time: 0.0083   lr: 0.00093221  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:44:58 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 639  total_loss: 0.3978  loss_cls: 0.1541  loss_box_reg: 0.2637  validation_loss: 0.4566    time: 0.1535  last_time: 0.1230  data_time: 0.0109  last_data_time: 0.0061   lr: 0.00096227  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:01 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 659  total_loss: 0.4776  loss_cls: 0.1764  loss_box_reg: 0.3012  validation_loss: 0.4566    time: 0.1533  last_time: 0.1251  data_time: 0.0112  last_data_time: 0.0060   lr: 0.00099232  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:04 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 679  total_loss: 0.5484  loss_cls: 0.1956  loss_box_reg: 0.3269  validation_loss: 0.4566    time: 0.1531  last_time: 0.1333  data_time: 0.0105  last_data_time: 0.0064   lr: 0.0010224  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:07 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 699  total_loss: 0.4515  loss_cls: 0.1666  loss_box_reg: 0.2815  validation_loss: 0.4566    time: 0.1533  last_time: 0.1509  data_time: 0.0102  last_data_time: 0.0065   lr: 0.0010524  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:10 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 719  total_loss: 0.4487  loss_cls: 0.1671  loss_box_reg: 0.2964  validation_loss: 0.4566    time: 0.1531  last_time: 0.1441  data_time: 0.0092  last_data_time: 0.0062   lr: 0.0010825  max_mem: 1938M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:45:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:45:12 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:45:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:45:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:45:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0021 s/iter. Inference: 0.0334 s/iter. Eval: 0.0005 s/iter. Total: 0.0359 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:45:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.654272 (0.040216 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.035065 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.545 | 26.990 | 18.117 | 18.993 | 33.538 | 22.314 |\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 39.437 | yol_kesisimi | 4.346 | futbol_sahası | 0.000 |\n",
      "| silo       | 22.395 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:45:15 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:45:15 d2.evaluation.testing]: \u001b[0mcopypaste: 16.5448,26.9895,18.1173,18.9934,33.5383,22.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.44558749988045493\n",
      "Validation loss improved to 0.4456 at iter 727\n",
      "\u001b[32m[10/15 11:45:19 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 739  total_loss: 0.54  loss_cls: 0.2042  loss_box_reg: 0.3316  validation_loss: 0.4456    time: 0.1531  last_time: 0.1492  data_time: 0.0129  last_data_time: 0.0281   lr: 0.0011125  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:22 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 759  total_loss: 0.5367  loss_cls: 0.2159  loss_box_reg: 0.3189  validation_loss: 0.4456    time: 0.1531  last_time: 0.1521  data_time: 0.0090  last_data_time: 0.0089   lr: 0.0011426  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:26 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 779  total_loss: 0.469  loss_cls: 0.1731  loss_box_reg: 0.2896  validation_loss: 0.4456    time: 0.1531  last_time: 0.1303  data_time: 0.0102  last_data_time: 0.0097   lr: 0.0011726  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:29 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 799  total_loss: 0.4888  loss_cls: 0.1748  loss_box_reg: 0.3105  validation_loss: 0.4456    time: 0.1532  last_time: 0.1310  data_time: 0.0094  last_data_time: 0.0067   lr: 0.0012027  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:32 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 819  total_loss: 0.397  loss_cls: 0.1424  loss_box_reg: 0.2475  validation_loss: 0.4456    time: 0.1534  last_time: 0.1950  data_time: 0.0121  last_data_time: 0.0072   lr: 0.0012328  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:35 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 839  total_loss: 0.4311  loss_cls: 0.1528  loss_box_reg: 0.2756  validation_loss: 0.4456    time: 0.1533  last_time: 0.1421  data_time: 0.0088  last_data_time: 0.0076   lr: 0.0012628  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:38 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 859  total_loss: 0.5019  loss_cls: 0.179  loss_box_reg: 0.3275  validation_loss: 0.4456    time: 0.1531  last_time: 0.1257  data_time: 0.0081  last_data_time: 0.0072   lr: 0.0012929  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:41 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 879  total_loss: 0.3739  loss_cls: 0.1373  loss_box_reg: 0.2366  validation_loss: 0.4456    time: 0.1529  last_time: 0.1287  data_time: 0.0107  last_data_time: 0.0115   lr: 0.0013229  max_mem: 1938M\n",
      "\u001b[32m[10/15 11:45:44 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 899  total_loss: 0.3959  loss_cls: 0.1483  loss_box_reg: 0.2531  validation_loss: 0.4456    time: 0.1528  last_time: 0.1308  data_time: 0.0114  last_data_time: 0.0077   lr: 0.001353  max_mem: 1938M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:45:45 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:45:45 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:45:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:45:45 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:45:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0026 s/iter. Inference: 0.0365 s/iter. Eval: 0.0006 s/iter. Total: 0.0397 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:45:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.605267 (0.039474 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.034532 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.436 | 34.544 | 20.969 | 16.780 | 35.537 | 36.318 |\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 40.404 | yol_kesisimi | 5.670 | futbol_sahası | 1.518 |\n",
      "| silo       | 34.154 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:45:49 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:45:49 d2.evaluation.testing]: \u001b[0mcopypaste: 20.4365,34.5439,20.9686,16.7802,35.5373,36.3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.42633868549281445\n",
      "Validation loss improved to 0.4263 at iter 909\n",
      "\u001b[32m[10/15 11:45:53 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 919  total_loss: 0.4683  loss_cls: 0.1701  loss_box_reg: 0.302  validation_loss: 0.4263    time: 0.1527  last_time: 0.1406  data_time: 0.0107  last_data_time: 0.0066   lr: 0.001383  max_mem: 1939M\n",
      "\u001b[32m[10/15 11:45:56 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 939  total_loss: 0.4716  loss_cls: 0.1542  loss_box_reg: 0.3227  validation_loss: 0.4263    time: 0.1527  last_time: 0.1317  data_time: 0.0113  last_data_time: 0.0092   lr: 0.0014131  max_mem: 1939M\n",
      "\u001b[32m[10/15 11:45:59 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 959  total_loss: 0.3836  loss_cls: 0.1473  loss_box_reg: 0.2391  validation_loss: 0.4263    time: 0.1524  last_time: 0.1327  data_time: 0.0090  last_data_time: 0.0095   lr: 0.0014431  max_mem: 1939M\n",
      "\u001b[32m[10/15 11:46:02 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 979  total_loss: 0.4768  loss_cls: 0.1609  loss_box_reg: 0.3087  validation_loss: 0.4263    time: 0.1525  last_time: 0.1547  data_time: 0.0112  last_data_time: 0.0119   lr: 0.0014732  max_mem: 1939M\n",
      "\u001b[32m[10/15 11:46:05 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 999  total_loss: 0.452  loss_cls: 0.1635  loss_box_reg: 0.2612  validation_loss: 0.4263    time: 0.1524  last_time: 0.1490  data_time: 0.0107  last_data_time: 0.0160   lr: 0.0015032  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:08 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1019  total_loss: 0.4716  loss_cls: 0.1738  loss_box_reg: 0.311  validation_loss: 0.4263    time: 0.1523  last_time: 0.1433  data_time: 0.0113  last_data_time: 0.0057   lr: 0.001486  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:11 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 1039  total_loss: 0.4881  loss_cls: 0.1747  loss_box_reg: 0.3187  validation_loss: 0.4263    time: 0.1524  last_time: 0.1570  data_time: 0.0108  last_data_time: 0.0065   lr: 0.0014661  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:14 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 1059  total_loss: 0.4195  loss_cls: 0.1451  loss_box_reg: 0.2719  validation_loss: 0.4263    time: 0.1523  last_time: 0.1562  data_time: 0.0102  last_data_time: 0.0173   lr: 0.0014459  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:17 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 1079  total_loss: 0.4074  loss_cls: 0.1446  loss_box_reg: 0.2602  validation_loss: 0.4263    time: 0.1523  last_time: 0.1560  data_time: 0.0106  last_data_time: 0.0140   lr: 0.0014256  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:46:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:46:19 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:46:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:46:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:46:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0017 s/iter. Inference: 0.0343 s/iter. Eval: 0.0005 s/iter. Total: 0.0364 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:46:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.517238 (0.038140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.033947 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.076 | 36.082 | 22.009 | 17.542 | 33.215 | 36.481 |\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.291 | yol_kesisimi | 6.722 | futbol_sahası | 1.302 |\n",
      "| silo       | 32.989 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:46:22 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:46:22 d2.evaluation.testing]: \u001b[0mcopypaste: 21.0760,36.0819,22.0090,17.5420,33.2147,36.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.40759501044808977\n",
      "Validation loss improved to 0.4076 at iter 1091\n",
      "\u001b[32m[10/15 11:46:26 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 1099  total_loss: 0.3109  loss_cls: 0.1173  loss_box_reg: 0.1952  validation_loss: 0.4076    time: 0.1525  last_time: 0.1637  data_time: 0.0123  last_data_time: 0.0078   lr: 0.0014051  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:29 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 1119  total_loss: 0.536  loss_cls: 0.1842  loss_box_reg: 0.3401  validation_loss: 0.4076    time: 0.1525  last_time: 0.1267  data_time: 0.0114  last_data_time: 0.0070   lr: 0.0013844  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:32 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 1139  total_loss: 0.3701  loss_cls: 0.139  loss_box_reg: 0.237  validation_loss: 0.4076    time: 0.1523  last_time: 0.1249  data_time: 0.0105  last_data_time: 0.0065   lr: 0.0013635  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:35 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 1159  total_loss: 0.4268  loss_cls: 0.1459  loss_box_reg: 0.2815  validation_loss: 0.4076    time: 0.1524  last_time: 0.1579  data_time: 0.0108  last_data_time: 0.0139   lr: 0.0013425  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:38 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 1179  total_loss: 0.4153  loss_cls: 0.1348  loss_box_reg: 0.2568  validation_loss: 0.4076    time: 0.1523  last_time: 0.1382  data_time: 0.0105  last_data_time: 0.0122   lr: 0.0013213  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:41 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 1199  total_loss: 0.3546  loss_cls: 0.1221  loss_box_reg: 0.2101  validation_loss: 0.4076    time: 0.1521  last_time: 0.1731  data_time: 0.0106  last_data_time: 0.0070   lr: 0.0013  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:44 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 1219  total_loss: 0.4091  loss_cls: 0.1665  loss_box_reg: 0.2539  validation_loss: 0.4076    time: 0.1521  last_time: 0.1763  data_time: 0.0091  last_data_time: 0.0076   lr: 0.0012785  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:47 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 1239  total_loss: 0.4519  loss_cls: 0.1381  loss_box_reg: 0.2971  validation_loss: 0.4076    time: 0.1520  last_time: 0.1427  data_time: 0.0106  last_data_time: 0.0070   lr: 0.0012569  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:46:50 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 1259  total_loss: 0.4899  loss_cls: 0.1716  loss_box_reg: 0.2986  validation_loss: 0.4076    time: 0.1521  last_time: 0.2862  data_time: 0.0101  last_data_time: 0.0224   lr: 0.0012353  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:46:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:46:52 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:46:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:46:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:46:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0021 s/iter. Inference: 0.0328 s/iter. Eval: 0.0004 s/iter. Total: 0.0354 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.449451 (0.037113 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:46:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.032544 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:46:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:46:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:46:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:46:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.413\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.394 | 37.309 | 23.229 | 22.037 | 32.849 | 29.811 |\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.787 | yol_kesisimi | 5.399 | futbol_sahası | 0.281 |\n",
      "| silo       | 40.108 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:46:56 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:46:56 d2.evaluation.testing]: \u001b[0mcopypaste: 22.3939,37.3088,23.2295,22.0366,32.8486,29.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3881525206838695\n",
      "Validation loss improved to 0.3882 at iter 1273\n",
      "\u001b[32m[10/15 11:46:59 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1279  total_loss: 0.4711  loss_cls: 0.1621  loss_box_reg: 0.3154  validation_loss: 0.3882    time: 0.1521  last_time: 0.1528  data_time: 0.0092  last_data_time: 0.0068   lr: 0.0012135  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:02 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 1299  total_loss: 0.3436  loss_cls: 0.1115  loss_box_reg: 0.2445  validation_loss: 0.3882    time: 0.1520  last_time: 0.1546  data_time: 0.0105  last_data_time: 0.0206   lr: 0.0011916  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:05 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 1319  total_loss: 0.4479  loss_cls: 0.17  loss_box_reg: 0.2687  validation_loss: 0.3882    time: 0.1520  last_time: 0.1453  data_time: 0.0149  last_data_time: 0.0075   lr: 0.0011697  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:08 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 1339  total_loss: 0.3768  loss_cls: 0.1252  loss_box_reg: 0.2428  validation_loss: 0.3882    time: 0.1520  last_time: 0.1436  data_time: 0.0126  last_data_time: 0.0069   lr: 0.0011477  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:11 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 1359  total_loss: 0.429  loss_cls: 0.15  loss_box_reg: 0.2672  validation_loss: 0.3882    time: 0.1521  last_time: 0.1398  data_time: 0.0089  last_data_time: 0.0085   lr: 0.0011256  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:14 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1379  total_loss: 0.398  loss_cls: 0.1347  loss_box_reg: 0.2659  validation_loss: 0.3882    time: 0.1520  last_time: 0.1445  data_time: 0.0113  last_data_time: 0.0101   lr: 0.0011035  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:17 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 1399  total_loss: 0.3325  loss_cls: 0.1199  loss_box_reg: 0.2127  validation_loss: 0.3882    time: 0.1520  last_time: 0.1438  data_time: 0.0087  last_data_time: 0.0063   lr: 0.0010813  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:20 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 1419  total_loss: 0.4305  loss_cls: 0.1433  loss_box_reg: 0.2879  validation_loss: 0.3882    time: 0.1518  last_time: 0.1664  data_time: 0.0101  last_data_time: 0.0100   lr: 0.0010591  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:23 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 1439  total_loss: 0.3222  loss_cls: 0.1147  loss_box_reg: 0.2012  validation_loss: 0.3882    time: 0.1519  last_time: 0.1307  data_time: 0.0113  last_data_time: 0.0052   lr: 0.001037  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:47:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:47:26 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:47:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:47:26 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:47:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0022 s/iter. Inference: 0.0338 s/iter. Eval: 0.0004 s/iter. Total: 0.0365 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:47:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.507600 (0.037994 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.033551 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.755\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.466 | 38.570 | 22.849 | 19.875 | 32.979 | 33.909 |\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 41.806 | yol_kesisimi | 6.769 | futbol_sahası | 0.529 |\n",
      "| silo       | 40.759 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:47:29 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:47:29 d2.evaluation.testing]: \u001b[0mcopypaste: 22.4659,38.5702,22.8490,19.8746,32.9792,33.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.41249315099607053\n",
      "No improvement in validation loss for 1 evaluations.\n",
      "\u001b[32m[10/15 11:47:32 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 1459  total_loss: 0.3824  loss_cls: 0.1332  loss_box_reg: 0.243  validation_loss: 0.4125    time: 0.1518  last_time: 0.1469  data_time: 0.0100  last_data_time: 0.0183   lr: 0.0010148  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:35 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 1479  total_loss: 0.4468  loss_cls: 0.1562  loss_box_reg: 0.29  validation_loss: 0.4125    time: 0.1518  last_time: 0.1452  data_time: 0.0109  last_data_time: 0.0106   lr: 0.00099255  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:38 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 1499  total_loss: 0.3182  loss_cls: 0.1052  loss_box_reg: 0.2145  validation_loss: 0.4125    time: 0.1518  last_time: 0.1638  data_time: 0.0120  last_data_time: 0.0234   lr: 0.00097037  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:41 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 1519  total_loss: 0.3189  loss_cls: 0.1197  loss_box_reg: 0.1952  validation_loss: 0.4125    time: 0.1518  last_time: 0.1646  data_time: 0.0098  last_data_time: 0.0063   lr: 0.00094822  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:44 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 1539  total_loss: 0.3471  loss_cls: 0.1186  loss_box_reg: 0.2282  validation_loss: 0.4125    time: 0.1517  last_time: 0.1447  data_time: 0.0104  last_data_time: 0.0094   lr: 0.0009261  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:47 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 1559  total_loss: 0.3222  loss_cls: 0.1085  loss_box_reg: 0.2138  validation_loss: 0.4125    time: 0.1517  last_time: 0.1588  data_time: 0.0119  last_data_time: 0.0076   lr: 0.00090402  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:50 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 1579  total_loss: 0.4395  loss_cls: 0.1458  loss_box_reg: 0.2922  validation_loss: 0.4125    time: 0.1516  last_time: 0.1430  data_time: 0.0089  last_data_time: 0.0067   lr: 0.000882  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:53 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 1599  total_loss: 0.4583  loss_cls: 0.159  loss_box_reg: 0.2824  validation_loss: 0.4125    time: 0.1515  last_time: 0.1434  data_time: 0.0101  last_data_time: 0.0069   lr: 0.00086005  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:47:56 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 1619  total_loss: 0.3215  loss_cls: 0.1025  loss_box_reg: 0.2116  validation_loss: 0.4125    time: 0.1518  last_time: 0.1586  data_time: 0.0145  last_data_time: 0.0095   lr: 0.00083818  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:47:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:47:59 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:47:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:47:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:47:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0025 s/iter. Inference: 0.0330 s/iter. Eval: 0.0005 s/iter. Total: 0.0360 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:48:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.087841 (0.046785 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.042279 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.596 | 39.575 | 24.030 | 21.439 | 34.061 | 32.758 |\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 42.976 | yol_kesisimi | 7.460 | futbol_sahası | 1.308 |\n",
      "| silo       | 42.640 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:48:03 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:48:03 d2.evaluation.testing]: \u001b[0mcopypaste: 23.5961,39.5748,24.0305,21.4388,34.0609,32.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3924866222684652\n",
      "No improvement in validation loss for 2 evaluations.\n",
      "\u001b[32m[10/15 11:48:06 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 1639  total_loss: 0.3244  loss_cls: 0.1102  loss_box_reg: 0.223  validation_loss: 0.3925    time: 0.1518  last_time: 0.1610  data_time: 0.0129  last_data_time: 0.0237   lr: 0.00081639  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:09 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 1659  total_loss: 0.377  loss_cls: 0.1288  loss_box_reg: 0.2501  validation_loss: 0.3925    time: 0.1518  last_time: 0.1559  data_time: 0.0141  last_data_time: 0.0222   lr: 0.00079471  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:12 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 1679  total_loss: 0.3283  loss_cls: 0.1002  loss_box_reg: 0.2281  validation_loss: 0.3925    time: 0.1519  last_time: 0.1274  data_time: 0.0117  last_data_time: 0.0104   lr: 0.00077313  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:15 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1699  total_loss: 0.3412  loss_cls: 0.122  loss_box_reg: 0.2064  validation_loss: 0.3925    time: 0.1519  last_time: 0.1527  data_time: 0.0102  last_data_time: 0.0102   lr: 0.00075166  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:18 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 1719  total_loss: 0.3384  loss_cls: 0.1129  loss_box_reg: 0.233  validation_loss: 0.3925    time: 0.1519  last_time: 0.1364  data_time: 0.0092  last_data_time: 0.0075   lr: 0.00073033  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:21 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 1739  total_loss: 0.3495  loss_cls: 0.1128  loss_box_reg: 0.2367  validation_loss: 0.3925    time: 0.1519  last_time: 0.1481  data_time: 0.0100  last_data_time: 0.0059   lr: 0.00070914  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:25 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 1759  total_loss: 0.3482  loss_cls: 0.1143  loss_box_reg: 0.234  validation_loss: 0.3925    time: 0.1520  last_time: 0.1536  data_time: 0.0113  last_data_time: 0.0089   lr: 0.00068809  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:28 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 1779  total_loss: 0.4289  loss_cls: 0.1351  loss_box_reg: 0.2738  validation_loss: 0.3925    time: 0.1521  last_time: 0.1341  data_time: 0.0125  last_data_time: 0.0078   lr: 0.0006672  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:31 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 1799  total_loss: 0.3979  loss_cls: 0.1313  loss_box_reg: 0.2647  validation_loss: 0.3925    time: 0.1521  last_time: 0.1738  data_time: 0.0122  last_data_time: 0.0246   lr: 0.00064648  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:48:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:48:34 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:48:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:48:34 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:48:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0022 s/iter. Inference: 0.0330 s/iter. Eval: 0.0005 s/iter. Total: 0.0356 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.529799 (0.038330 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.033747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.471 | 38.910 | 23.150 | 22.342 | 33.508 | 34.916 |\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 41.891 | yol_kesisimi | 8.201 | futbol_sahası | 0.856 |\n",
      "| silo       | 42.937 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:48:37 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:48:37 d2.evaluation.testing]: \u001b[0mcopypaste: 23.4715,38.9096,23.1496,22.3416,33.5075,34.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4065186273778828\n",
      "\u001b[32m[10/15 11:48:40 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1819  total_loss: 0.2912  loss_cls: 0.1021  loss_box_reg: 0.1973  validation_loss: 0.4065    time: 0.1521  last_time: 0.1371  data_time: 0.0096  last_data_time: 0.0101   lr: 0.00062593  max_mem: 1940M\n",
      "No improvement in validation loss for 3 evaluations.\n",
      "\u001b[32m[10/15 11:48:43 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 1839  total_loss: 0.3456  loss_cls: 0.1178  loss_box_reg: 0.2288  validation_loss: 0.4065    time: 0.1520  last_time: 0.1303  data_time: 0.0089  last_data_time: 0.0124   lr: 0.00060558  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:46 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 1859  total_loss: 0.4203  loss_cls: 0.1379  loss_box_reg: 0.2687  validation_loss: 0.4065    time: 0.1521  last_time: 0.1732  data_time: 0.0107  last_data_time: 0.0096   lr: 0.00058542  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:49 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 1879  total_loss: 0.3777  loss_cls: 0.1205  loss_box_reg: 0.2519  validation_loss: 0.4065    time: 0.1520  last_time: 0.1486  data_time: 0.0098  last_data_time: 0.0059   lr: 0.00056546  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:52 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 1899  total_loss: 0.3878  loss_cls: 0.1313  loss_box_reg: 0.2601  validation_loss: 0.4065    time: 0.1520  last_time: 0.1383  data_time: 0.0104  last_data_time: 0.0090   lr: 0.00054573  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:55 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 1919  total_loss: 0.3573  loss_cls: 0.1193  loss_box_reg: 0.238  validation_loss: 0.4065    time: 0.1518  last_time: 0.1425  data_time: 0.0095  last_data_time: 0.0109   lr: 0.00052621  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:48:58 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 1939  total_loss: 0.3673  loss_cls: 0.1119  loss_box_reg: 0.2494  validation_loss: 0.4065    time: 0.1519  last_time: 0.1535  data_time: 0.0108  last_data_time: 0.0177   lr: 0.00050693  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:01 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 1959  total_loss: 0.3424  loss_cls: 0.1209  loss_box_reg: 0.2189  validation_loss: 0.4065    time: 0.1520  last_time: 0.1393  data_time: 0.0142  last_data_time: 0.0207   lr: 0.0004879  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:04 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 1979  total_loss: 0.3038  loss_cls: 0.1046  loss_box_reg: 0.2044  validation_loss: 0.4065    time: 0.1519  last_time: 0.1409  data_time: 0.0089  last_data_time: 0.0106   lr: 0.00046911  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:07 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 1999  total_loss: 0.4017  loss_cls: 0.1385  loss_box_reg: 0.2659  validation_loss: 0.4065    time: 0.1519  last_time: 0.1717  data_time: 0.0107  last_data_time: 0.0109   lr: 0.00045059  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:49:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:49:07 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:49:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:49:07 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:49:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0017 s/iter. Inference: 0.0332 s/iter. Eval: 0.0005 s/iter. Total: 0.0354 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:49:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.404227 (0.036428 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.032251 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.313 | 39.703 | 24.447 | 22.784 | 33.775 | 32.544 |\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 44.666 | yol_kesisimi | 7.460 | futbol_sahası | 0.842 |\n",
      "| silo       | 44.286 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:49:10 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:49:10 d2.evaluation.testing]: \u001b[0mcopypaste: 24.3134,39.7027,24.4470,22.7844,33.7755,32.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3822966447808373\n",
      "Validation loss improved to 0.3823 at iter 2001\n",
      "\u001b[32m[10/15 11:49:16 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 2019  total_loss: 0.3982  loss_cls: 0.1222  loss_box_reg: 0.2729  validation_loss: 0.3823    time: 0.1518  last_time: 0.1463  data_time: 0.0106  last_data_time: 0.0150   lr: 0.00043234  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:18 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2039  total_loss: 0.3179  loss_cls: 0.0921  loss_box_reg: 0.2019  validation_loss: 0.3823    time: 0.1517  last_time: 0.1303  data_time: 0.0102  last_data_time: 0.0085   lr: 0.00041436  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:21 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 2059  total_loss: 0.3424  loss_cls: 0.1181  loss_box_reg: 0.2285  validation_loss: 0.3823    time: 0.1516  last_time: 0.1402  data_time: 0.0088  last_data_time: 0.0062   lr: 0.00039667  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:24 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2079  total_loss: 0.3168  loss_cls: 0.1099  loss_box_reg: 0.2093  validation_loss: 0.3823    time: 0.1515  last_time: 0.1610  data_time: 0.0120  last_data_time: 0.0108   lr: 0.00037928  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:27 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2099  total_loss: 0.3412  loss_cls: 0.122  loss_box_reg: 0.2192  validation_loss: 0.3823    time: 0.1516  last_time: 0.2188  data_time: 0.0126  last_data_time: 0.0213   lr: 0.00036218  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:30 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 2119  total_loss: 0.3552  loss_cls: 0.1122  loss_box_reg: 0.2337  validation_loss: 0.3823    time: 0.1516  last_time: 0.1599  data_time: 0.0121  last_data_time: 0.0241   lr: 0.0003454  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:33 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2139  total_loss: 0.4156  loss_cls: 0.1264  loss_box_reg: 0.2487  validation_loss: 0.3823    time: 0.1516  last_time: 0.1542  data_time: 0.0124  last_data_time: 0.0085   lr: 0.00032894  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:36 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 2159  total_loss: 0.3482  loss_cls: 0.1089  loss_box_reg: 0.2307  validation_loss: 0.3823    time: 0.1516  last_time: 0.1243  data_time: 0.0089  last_data_time: 0.0057   lr: 0.00031281  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:39 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 2179  total_loss: 0.3401  loss_cls: 0.1231  loss_box_reg: 0.2253  validation_loss: 0.3823    time: 0.1516  last_time: 0.1311  data_time: 0.0100  last_data_time: 0.0091   lr: 0.00029701  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:49:40 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:49:40 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:49:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:49:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:49:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0017 s/iter. Inference: 0.0335 s/iter. Eval: 0.0005 s/iter. Total: 0.0357 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:49:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.432091 (0.036850 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.032584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.960 | 40.473 | 24.062 | 23.130 | 33.244 | 35.539 |\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.996 | yol_kesisimi | 7.912 | futbol_sahası | 1.201 |\n",
      "| silo       | 42.731 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:49:43 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:49:43 d2.evaluation.testing]: \u001b[0mcopypaste: 23.9600,40.4732,24.0615,23.1300,33.2442,35.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3910457128790063\n",
      "No improvement in validation loss for 1 evaluations.\n",
      "\u001b[32m[10/15 11:49:48 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 2199  total_loss: 0.3238  loss_cls: 0.1116  loss_box_reg: 0.2092  validation_loss: 0.391    time: 0.1516  last_time: 0.1251  data_time: 0.0096  last_data_time: 0.0075   lr: 0.00028155  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:51 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 2219  total_loss: 0.3835  loss_cls: 0.1248  loss_box_reg: 0.2747  validation_loss: 0.391    time: 0.1516  last_time: 0.1525  data_time: 0.0108  last_data_time: 0.0075   lr: 0.00026644  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:54 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2239  total_loss: 0.3079  loss_cls: 0.1113  loss_box_reg: 0.1932  validation_loss: 0.391    time: 0.1516  last_time: 0.1817  data_time: 0.0098  last_data_time: 0.0111   lr: 0.00025168  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:49:57 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2259  total_loss: 0.4249  loss_cls: 0.1379  loss_box_reg: 0.291  validation_loss: 0.391    time: 0.1515  last_time: 0.1433  data_time: 0.0139  last_data_time: 0.0068   lr: 0.00023729  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:00 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2279  total_loss: 0.3126  loss_cls: 0.1043  loss_box_reg: 0.2271  validation_loss: 0.391    time: 0.1515  last_time: 0.1665  data_time: 0.0089  last_data_time: 0.0054   lr: 0.00022327  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:03 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2299  total_loss: 0.2809  loss_cls: 0.1081  loss_box_reg: 0.1583  validation_loss: 0.391    time: 0.1515  last_time: 0.1657  data_time: 0.0109  last_data_time: 0.0080   lr: 0.00020962  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:06 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 2319  total_loss: 0.3333  loss_cls: 0.1154  loss_box_reg: 0.2228  validation_loss: 0.391    time: 0.1515  last_time: 0.1340  data_time: 0.0126  last_data_time: 0.0090   lr: 0.00019636  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:09 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 2339  total_loss: 0.3899  loss_cls: 0.1222  loss_box_reg: 0.2546  validation_loss: 0.391    time: 0.1515  last_time: 0.1728  data_time: 0.0116  last_data_time: 0.0071   lr: 0.00018349  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:12 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2359  total_loss: 0.3085  loss_cls: 0.1195  loss_box_reg: 0.1994  validation_loss: 0.391    time: 0.1514  last_time: 0.1248  data_time: 0.0093  last_data_time: 0.0065   lr: 0.00017101  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:50:13 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:50:13 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:50:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:50:13 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:50:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0016 s/iter. Inference: 0.0326 s/iter. Eval: 0.0005 s/iter. Total: 0.0347 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:50:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.402042 (0.036395 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.032464 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.406\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.971 | 40.559 | 23.893 | 23.854 | 33.371 | 34.406 |\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.920 | yol_kesisimi | 7.622 | futbol_sahası | 1.242 |\n",
      "| silo       | 43.098 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:50:16 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:50:16 d2.evaluation.testing]: \u001b[0mcopypaste: 23.9705,40.5586,23.8935,23.8536,33.3711,34.4064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.38104022771749696\n",
      "Validation loss improved to 0.3810 at iter 2365\n",
      "\u001b[32m[10/15 11:50:21 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 2379  total_loss: 0.2669  loss_cls: 0.08502  loss_box_reg: 0.1748  validation_loss: 0.381    time: 0.1514  last_time: 0.2185  data_time: 0.0092  last_data_time: 0.0082   lr: 0.00015893  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:24 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 2399  total_loss: 0.4186  loss_cls: 0.1368  loss_box_reg: 0.2646  validation_loss: 0.381    time: 0.1515  last_time: 0.2514  data_time: 0.0105  last_data_time: 0.0171   lr: 0.00014726  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:28 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2419  total_loss: 0.3316  loss_cls: 0.1197  loss_box_reg: 0.2161  validation_loss: 0.381    time: 0.1515  last_time: 0.1288  data_time: 0.0107  last_data_time: 0.0058   lr: 0.000136  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:30 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 2439  total_loss: 0.3284  loss_cls: 0.1105  loss_box_reg: 0.2237  validation_loss: 0.381    time: 0.1515  last_time: 0.1393  data_time: 0.0100  last_data_time: 0.0067   lr: 0.00012515  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:33 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 2459  total_loss: 0.3533  loss_cls: 0.1265  loss_box_reg: 0.234  validation_loss: 0.381    time: 0.1515  last_time: 0.1390  data_time: 0.0108  last_data_time: 0.0099   lr: 0.00011473  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:37 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 2479  total_loss: 0.4157  loss_cls: 0.1245  loss_box_reg: 0.2744  validation_loss: 0.381    time: 0.1516  last_time: 0.2342  data_time: 0.0121  last_data_time: 0.0062   lr: 0.00010474  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:40 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 2499  total_loss: 0.3584  loss_cls: 0.1248  loss_box_reg: 0.2344  validation_loss: 0.381    time: 0.1516  last_time: 0.2057  data_time: 0.0096  last_data_time: 0.0103   lr: 9.5178e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:43 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2519  total_loss: 0.3678  loss_cls: 0.1271  loss_box_reg: 0.2504  validation_loss: 0.381    time: 0.1516  last_time: 0.2169  data_time: 0.0101  last_data_time: 0.0162   lr: 8.6053e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:46 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 2539  total_loss: 0.397  loss_cls: 0.128  loss_box_reg: 0.2622  validation_loss: 0.381    time: 0.1516  last_time: 0.1279  data_time: 0.0112  last_data_time: 0.0088   lr: 7.7368e-05  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:50:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:50:47 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:50:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:50:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:50:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0020 s/iter. Inference: 0.0341 s/iter. Eval: 0.0005 s/iter. Total: 0.0366 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:50:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.504688 (0.037950 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:50:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.033414 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:50:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:50:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:50:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.455 | 40.389 | 23.758 | 23.299 | 33.277 | 33.403 |\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.919 | yol_kesisimi | 7.171 | futbol_sahası | 1.047 |\n",
      "| silo       | 41.685 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:50:51 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:50:51 d2.evaluation.testing]: \u001b[0mcopypaste: 23.4554,40.3893,23.7579,23.2994,33.2765,33.4032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3916382631680495\n",
      "No improvement in validation loss for 1 evaluations.\n",
      "\u001b[32m[10/15 11:50:55 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 2559  total_loss: 0.2829  loss_cls: 0.0946  loss_box_reg: 0.1912  validation_loss: 0.3916    time: 0.1516  last_time: 0.1416  data_time: 0.0103  last_data_time: 0.0076   lr: 6.9128e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:50:58 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2579  total_loss: 0.3032  loss_cls: 0.1024  loss_box_reg: 0.2049  validation_loss: 0.3916    time: 0.1516  last_time: 0.1531  data_time: 0.0095  last_data_time: 0.0091   lr: 6.1336e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:01 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 2599  total_loss: 0.2775  loss_cls: 0.1052  loss_box_reg: 0.1852  validation_loss: 0.3916    time: 0.1515  last_time: 0.1714  data_time: 0.0111  last_data_time: 0.0190   lr: 5.3997e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:05 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 2619  total_loss: 0.3723  loss_cls: 0.1336  loss_box_reg: 0.2244  validation_loss: 0.3916    time: 0.1516  last_time: 0.2263  data_time: 0.0112  last_data_time: 0.0231   lr: 4.7113e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:08 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 2639  total_loss: 0.3061  loss_cls: 0.09691  loss_box_reg: 0.2061  validation_loss: 0.3916    time: 0.1516  last_time: 0.1465  data_time: 0.0119  last_data_time: 0.0150   lr: 4.0689e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:11 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 2659  total_loss: 0.4045  loss_cls: 0.147  loss_box_reg: 0.2563  validation_loss: 0.3916    time: 0.1516  last_time: 0.1461  data_time: 0.0122  last_data_time: 0.0263   lr: 3.4726e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:14 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 2679  total_loss: 0.2956  loss_cls: 0.1017  loss_box_reg: 0.197  validation_loss: 0.3916    time: 0.1516  last_time: 0.1501  data_time: 0.0109  last_data_time: 0.0055   lr: 2.9228e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:16 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 2699  total_loss: 0.32  loss_cls: 0.117  loss_box_reg: 0.2209  validation_loss: 0.3916    time: 0.1515  last_time: 0.1390  data_time: 0.0099  last_data_time: 0.0068   lr: 2.4197e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:19 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2719  total_loss: 0.2621  loss_cls: 0.09101  loss_box_reg: 0.1761  validation_loss: 0.3916    time: 0.1514  last_time: 0.1457  data_time: 0.0091  last_data_time: 0.0067   lr: 1.9636e-05  max_mem: 1940M\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:51:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:51:21 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:51:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:51:21 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:51:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0020 s/iter. Inference: 0.0330 s/iter. Eval: 0.0005 s/iter. Total: 0.0355 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:51:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.406745 (0.036466 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.032224 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.745 | 39.968 | 23.807 | 23.954 | 33.126 | 33.740 |\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.937 | yol_kesisimi | 6.912 | futbol_sahası | 1.032 |\n",
      "| silo       | 43.101 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:51:24 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:51:24 d2.evaluation.testing]: \u001b[0mcopypaste: 23.7453,39.9677,23.8072,23.9543,33.1262,33.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3874721528673676\n",
      "No improvement in validation loss for 2 evaluations.\n",
      "\u001b[32m[10/15 11:51:28 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 2739  total_loss: 0.317  loss_cls: 0.102  loss_box_reg: 0.2107  validation_loss: 0.3875    time: 0.1514  last_time: 0.1489  data_time: 0.0095  last_data_time: 0.0092   lr: 1.5547e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:31 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 2759  total_loss: 0.2876  loss_cls: 0.09077  loss_box_reg: 0.1988  validation_loss: 0.3875    time: 0.1514  last_time: 0.1450  data_time: 0.0111  last_data_time: 0.0073   lr: 1.1931e-05  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:34 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 2779  total_loss: 0.3851  loss_cls: 0.1191  loss_box_reg: 0.2538  validation_loss: 0.3875    time: 0.1514  last_time: 0.1787  data_time: 0.0135  last_data_time: 0.0234   lr: 8.791e-06  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:37 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 2799  total_loss: 0.3194  loss_cls: 0.1041  loss_box_reg: 0.1997  validation_loss: 0.3875    time: 0.1514  last_time: 0.1416  data_time: 0.0103  last_data_time: 0.0086   lr: 6.1277e-06  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:40 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2819  total_loss: 0.2986  loss_cls: 0.09589  loss_box_reg: 0.1988  validation_loss: 0.3875    time: 0.1515  last_time: 0.1946  data_time: 0.0135  last_data_time: 0.0417   lr: 3.9426e-06  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:43 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 2839  total_loss: 0.3227  loss_cls: 0.1184  loss_box_reg: 0.2257  validation_loss: 0.3875    time: 0.1515  last_time: 0.1495  data_time: 0.0119  last_data_time: 0.0162   lr: 2.2366e-06  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:46 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2859  total_loss: 0.3761  loss_cls: 0.1163  loss_box_reg: 0.2621  validation_loss: 0.3875    time: 0.1514  last_time: 0.1379  data_time: 0.0091  last_data_time: 0.0095   lr: 1.0106e-06  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:49 d2.utils.events]: \u001b[0m eta: 0:00:02  iter: 2879  total_loss: 0.3172  loss_cls: 0.1081  loss_box_reg: 0.2172  validation_loss: 0.3875    time: 0.1514  last_time: 0.1463  data_time: 0.0098  last_data_time: 0.0106   lr: 2.6516e-07  max_mem: 1940M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3826464060956324\n",
      "\u001b[32m[10/15 11:51:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2899  total_loss: 0.3569  loss_cls: 0.1245  loss_box_reg: 0.2318  validation_loss: 0.3826    time: 0.1514  last_time: 0.1389  data_time: 0.0105  last_data_time: 0.0068   lr: 6.013e-10  max_mem: 1940M\n",
      "\u001b[32m[10/15 11:51:55 d2.engine.hooks]: \u001b[0mOverall training speed: 2898 iterations in 0:07:18 (0.1514 s / it)\n",
      "\u001b[32m[10/15 11:51:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:09:07 (0:01:48 on hooks)\n",
      "[AlbumentationsMapper] Augmentations used in inference: Compose([\n",
      "], p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['category_ids'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True, 'clip': False}, keypoint_params=None, additional_targets={}, is_check_shapes=True)\n",
      "Loading from cache dataset_dicts_cache_original_debug0.pkl\n",
      "\u001b[32m[10/15 11:51:55 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/15 11:51:55 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/15 11:51:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/15 11:51:55 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/15 11:51:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 71 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:191: UserWarning:\n",
      "\n",
      "Got processor for bboxes, but no transform to process it.\n",
      "\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:51:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/71. Dataloading: 0.0014 s/iter. Inference: 0.0337 s/iter. Eval: 0.0005 s/iter. Total: 0.0356 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning:\n",
      "\n",
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/15 11:51:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.515483 (0.038113 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:51:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.033717 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/15 11:51:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/15 11:51:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/v1/inference/coco_instances_results.json\n",
      "\u001b[32m[10/15 11:51:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/15 11:51:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.679 | 39.964 | 23.559 | 23.895 | 33.060 | 33.702 |\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP    | category      | AP    |\n",
      "|:-----------|:-------|:-------------|:------|:--------------|:------|\n",
      "| bina       | 43.721 | yol_kesisimi | 6.876 | futbol_sahası | 1.018 |\n",
      "| silo       | 43.100 |              |       |               |       |\n",
      "\u001b[32m[10/15 11:51:59 d2.engine.defaults]: \u001b[0mEvaluation results for sayzek_valid in csv format:\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/15 11:51:59 d2.evaluation.testing]: \u001b[0mcopypaste: 23.6786,39.9640,23.5591,23.8949,33.0596,33.7021\n"
     ]
    }
   ],
   "source": [
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:51:59.109228Z",
     "iopub.status.busy": "2024-10-15T11:51:59.107315Z",
     "iopub.status.idle": "2024-10-15T11:51:59.163473Z",
     "shell.execute_reply": "2024-10-15T11:51:59.162558Z",
     "shell.execute_reply.started": "2024-10-15T11:51:59.109171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_time</th>\n",
       "      <th>eta_seconds</th>\n",
       "      <th>iteration</th>\n",
       "      <th>loss_box_reg</th>\n",
       "      <th>loss_cls</th>\n",
       "      <th>lr</th>\n",
       "      <th>num_pos_anchors</th>\n",
       "      <th>rank_data_time</th>\n",
       "      <th>time</th>\n",
       "      <th>total_loss</th>\n",
       "      <th>bbox/AP</th>\n",
       "      <th>bbox/AP-bina</th>\n",
       "      <th>bbox/AP-futbol_sahası</th>\n",
       "      <th>bbox/AP-silo</th>\n",
       "      <th>bbox/AP-yol_kesisimi</th>\n",
       "      <th>bbox/AP50</th>\n",
       "      <th>bbox/AP75</th>\n",
       "      <th>bbox/APl</th>\n",
       "      <th>bbox/APm</th>\n",
       "      <th>bbox/APs</th>\n",
       "      <th>validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006041</td>\n",
       "      <td>423.526152</td>\n",
       "      <td>19</td>\n",
       "      <td>0.915418</td>\n",
       "      <td>0.925530</td>\n",
       "      <td>3.060060e-05</td>\n",
       "      <td>222.75</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.147058</td>\n",
       "      <td>1.827620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008879</td>\n",
       "      <td>432.520481</td>\n",
       "      <td>39</td>\n",
       "      <td>0.471108</td>\n",
       "      <td>0.601976</td>\n",
       "      <td>6.065440e-05</td>\n",
       "      <td>245.75</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.154664</td>\n",
       "      <td>1.106187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008747</td>\n",
       "      <td>433.437939</td>\n",
       "      <td>59</td>\n",
       "      <td>0.401081</td>\n",
       "      <td>0.594678</td>\n",
       "      <td>9.070820e-05</td>\n",
       "      <td>317.00</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.155635</td>\n",
       "      <td>0.975931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008395</td>\n",
       "      <td>426.471244</td>\n",
       "      <td>79</td>\n",
       "      <td>0.418714</td>\n",
       "      <td>0.492615</td>\n",
       "      <td>1.207620e-04</td>\n",
       "      <td>253.75</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>0.147338</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009491</td>\n",
       "      <td>420.573558</td>\n",
       "      <td>99</td>\n",
       "      <td>0.410167</td>\n",
       "      <td>0.424832</td>\n",
       "      <td>1.508158e-04</td>\n",
       "      <td>250.25</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.146228</td>\n",
       "      <td>0.844841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.011034</td>\n",
       "      <td>8.660344</td>\n",
       "      <td>2839</td>\n",
       "      <td>0.225667</td>\n",
       "      <td>0.118416</td>\n",
       "      <td>2.236608e-06</td>\n",
       "      <td>243.75</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.322740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.007144</td>\n",
       "      <td>5.761426</td>\n",
       "      <td>2859</td>\n",
       "      <td>0.262058</td>\n",
       "      <td>0.116282</td>\n",
       "      <td>1.010612e-06</td>\n",
       "      <td>272.00</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.143444</td>\n",
       "      <td>0.376067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.007757</td>\n",
       "      <td>2.879027</td>\n",
       "      <td>2879</td>\n",
       "      <td>0.217166</td>\n",
       "      <td>0.108142</td>\n",
       "      <td>2.651601e-07</td>\n",
       "      <td>283.00</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.141237</td>\n",
       "      <td>0.317164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2899</td>\n",
       "      <td>0.231787</td>\n",
       "      <td>0.124484</td>\n",
       "      <td>6.012958e-10</td>\n",
       "      <td>278.00</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.356922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.678592</td>\n",
       "      <td>43.721051</td>\n",
       "      <td>1.017602</td>\n",
       "      <td>43.100128</td>\n",
       "      <td>6.875589</td>\n",
       "      <td>39.963958</td>\n",
       "      <td>23.559148</td>\n",
       "      <td>33.702125</td>\n",
       "      <td>33.05963</td>\n",
       "      <td>23.894948</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_time  eta_seconds  iteration  loss_box_reg  loss_cls            lr  \\\n",
       "0     0.006041   423.526152         19      0.915418  0.925530  3.060060e-05   \n",
       "1     0.008879   432.520481         39      0.471108  0.601976  6.065440e-05   \n",
       "2     0.008747   433.437939         59      0.401081  0.594678  9.070820e-05   \n",
       "3     0.008395   426.471244         79      0.418714  0.492615  1.207620e-04   \n",
       "4     0.009491   420.573558         99      0.410167  0.424832  1.508158e-04   \n",
       "..         ...          ...        ...           ...       ...           ...   \n",
       "155   0.011034     8.660344       2839      0.225667  0.118416  2.236608e-06   \n",
       "156   0.007144     5.761426       2859      0.262058  0.116282  1.010612e-06   \n",
       "157   0.007757     2.879027       2879      0.217166  0.108142  2.651601e-07   \n",
       "158   0.008825     0.000000       2899      0.231787  0.124484  6.012958e-10   \n",
       "159        NaN          NaN       2900           NaN       NaN           NaN   \n",
       "\n",
       "     num_pos_anchors  rank_data_time      time  total_loss    bbox/AP  \\\n",
       "0             222.75        0.006041  0.147058    1.827620        NaN   \n",
       "1             245.75        0.008879  0.154664    1.106187        NaN   \n",
       "2             317.00        0.008747  0.155635    0.975931        NaN   \n",
       "3             253.75        0.008395  0.147338    0.880194        NaN   \n",
       "4             250.25        0.009491  0.146228    0.844841        NaN   \n",
       "..               ...             ...       ...         ...        ...   \n",
       "155           243.75        0.011034  0.143713    0.322740        NaN   \n",
       "156           272.00        0.007144  0.143444    0.376067        NaN   \n",
       "157           283.00        0.007757  0.141237    0.317164        NaN   \n",
       "158           278.00        0.008825  0.147600    0.356922        NaN   \n",
       "159              NaN             NaN       NaN         NaN  23.678592   \n",
       "\n",
       "     bbox/AP-bina  bbox/AP-futbol_sahası  bbox/AP-silo  bbox/AP-yol_kesisimi  \\\n",
       "0             NaN                    NaN           NaN                   NaN   \n",
       "1             NaN                    NaN           NaN                   NaN   \n",
       "2             NaN                    NaN           NaN                   NaN   \n",
       "3             NaN                    NaN           NaN                   NaN   \n",
       "4             NaN                    NaN           NaN                   NaN   \n",
       "..            ...                    ...           ...                   ...   \n",
       "155           NaN                    NaN           NaN                   NaN   \n",
       "156           NaN                    NaN           NaN                   NaN   \n",
       "157           NaN                    NaN           NaN                   NaN   \n",
       "158           NaN                    NaN           NaN                   NaN   \n",
       "159     43.721051               1.017602     43.100128              6.875589   \n",
       "\n",
       "     bbox/AP50  bbox/AP75   bbox/APl  bbox/APm   bbox/APs  validation_loss  \n",
       "0          NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "1          NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "2          NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "3          NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "4          NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "..         ...        ...        ...       ...        ...              ...  \n",
       "155        NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "156        NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "157        NaN        NaN        NaN       NaN        NaN              NaN  \n",
       "158        NaN        NaN        NaN       NaN        NaN         0.382646  \n",
       "159  39.963958  23.559148  33.702125  33.05963  23.894948              NaN  \n",
       "\n",
       "[160 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.read_json(outdir / \"metrics.json\", orient=\"records\", lines=True)\n",
    "mdf = metrics_df.sort_values(\"iteration\")\n",
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:51:59.165129Z",
     "iopub.status.busy": "2024-10-15T11:51:59.164747Z",
     "iopub.status.idle": "2024-10-15T11:51:59.504190Z",
     "shell.execute_reply": "2024-10-15T11:51:59.503416Z",
     "shell.execute_reply.started": "2024-10-15T11:51:59.165087Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Loss curve\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "mdf1 = mdf[~mdf[\"total_loss\"].isna()]\n",
    "ax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\n",
    "if \"validation_loss\" in mdf.columns:\n",
    "    mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n",
    "    ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"], c=\"C1\", label=\"validation\")\n",
    "\n",
    "# ax.set_ylim([0, 0.5])\n",
    "ax.legend()\n",
    "ax.set_title(\"Loss curve\")\n",
    "plt.show()\n",
    "plt.savefig(outdir/\"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:51:59.505622Z",
     "iopub.status.busy": "2024-10-15T11:51:59.505320Z",
     "iopub.status.idle": "2024-10-15T11:51:59.799094Z",
     "shell.execute_reply": "2024-10-15T11:51:59.798233Z",
     "shell.execute_reply.started": "2024-10-15T11:51:59.505589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mdf3 = mdf[~mdf[\"bbox/AP50\"].isna()]\n",
    "\n",
    "ax.plot(mdf3[\"iteration\"], mdf3[\"bbox/AP50\"] / 100., c=\"C2\", label=\"validation\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"mAP@50\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"mAP\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(outdir / \"mAP50.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T11:51:59.800709Z",
     "iopub.status.busy": "2024-10-15T11:51:59.800368Z",
     "iopub.status.idle": "2024-10-15T11:52:00.073433Z",
     "shell.execute_reply": "2024-10-15T11:52:00.072440Z",
     "shell.execute_reply.started": "2024-10-15T11:51:59.800661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "mdf_bbox_class = mdf3.iloc[-1][[f\"bbox/AP-{col}\" for col in thing_classes]]\n",
    "mdf_bbox_class.plot(kind=\"bar\", ax=ax)\n",
    "_ = ax.set_title(\"AP by class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5860415,
     "sourceId": 9605314,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
